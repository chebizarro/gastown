{"action":"create","id":"gt-nostr-epic","title":"[EPIC] Gastown Nostr-Native Refactor","type":"epic","priority":"critical","description":"# Gastown Nostr-Native Refactor\n\nRefactor Gastown from a beads-backed local orchestration layer into a **Nostr-native system**, bridging beads issue tracking, and using Flotilla/Budabit as the Discord-like web frontend.\n\n## Architectural Decisions\n\n- **Authority for replaceable state**: Deacon pubkey (single canonical publisher avoids NIP-33 conflicts)\n- **Key management**: NIP-46 external signer (bunker) — no nsec on disk\n- **Issue payload size**: Full dependency graph, heavy blobs offloaded to Blossom servers\n- **Offline/relay outage**: Spool to local event store with exponential backoff drain\n\n## Event Kind Allocation\n\n| Kind | Name | Purpose |\n|------|------|--------|\n| 30315 | LOG_STATUS | Activity feed (replaces .events.jsonl) |\n| 30316 | LIFECYCLE | Agent presence (replaces .runtime/*.json) |\n| 30318 | GT_CONVOY_STATE | Convoy progress (replaces bd dep list) |\n| 30319 | GT_BEADS_ISSUE_STATE | Issue mirror for UI |\n| 30320 | GT_PROTOCOL_EVENT | Machine-to-machine protocol |\n| 30321 | GT_GROUP_DEF | Group definitions |\n| 30322 | GT_QUEUE_DEF | Work queue definitions |\n| 30323 | GT_CHANNEL_DEF | Channel definitions |\n| 30325 | GT_WORK_ITEM | Queue work items |\n\n## Communication Model\n\n| Pattern | Nostr Mapping |\n|---------|---------------|\n| Human ↔ Agent conversation | NIP-17 DM (kind 14 gift-wrapped) |\n| Rig/town broadcast | NIP-28 channel (kind 42) |\n| Machine protocol | Custom kind 30320 |\n| Session handoff | NIP-17 DM to self/successor |\n| Work queue items | Custom kind 30325 |\n\n## Phases\n\n1. Protocol Spec & Config (gt-nostr-p1)\n2. Publisher Package & Agent Identity (gt-nostr-p2)\n2.5. LLM Client Abstraction & Network Agent Loop (gt-nostr-p2.5)\n3. Dual-Write Activity Logs (gt-nostr-p3)\n4. Lifecycle Signaling (gt-nostr-p4)\n5. Convoy & Issue Mirrors (gt-nostr-p5)\n6. Protocol Events & Work Queues (gt-nostr-p6)\n7. Chat & Channel Integration (gt-nostr-p7)\n8. Flotilla Extension Development (gt-nostr-ext)\n9. Flotilla Extension Shipping & Verification (gt-nostr-p8)\n10. Sunset Local Paths (gt-nostr-p9)\n\n## Reference\n\n- Spec: `docs/design/nostr-protocol.md` (v0.3.0)\n- AI-Hub Compendium: `ai-hub/docs/compendium/05_data_flow_and_nostr_events.md`\n- Flotilla Extension: `gastown-flotilla-extension/` (standalone repo, no Budabit core edits)\n- Go Nostr Library: `fiatjaf.com/nostr` (NOT github.com/nbd-wtf/go-nostr)"}
{"action":"create","id":"gt-nostr-p1","title":"[P1] Nostr Protocol Spec & Config Infrastructure","type":"task","priority":"critical","description":"# Phase 1: Nostr Protocol Spec & Config Infrastructure\n\n**Parent Epic**: gt-nostr-epic\n**Blocks**: gt-nostr-p2, gt-nostr-p3, gt-nostr-p4, gt-nostr-p5, gt-nostr-p6, gt-nostr-p7, gt-nostr-p8, gt-nostr-p9\n**Estimated Effort**: Medium\n\n## Objective\n\nFinalize the protocol specification and implement the config infrastructure that all subsequent phases depend on. This is the foundation — every Nostr feature reads from these config structures.\n\n## Deliverables\n\n### 1. Protocol Specification (DONE — Review)\n\n- [x] `docs/design/nostr-protocol.md` v0.2.0 created\n- [ ] Final review pass — validate all event kind schemas against AI-Hub compendium\n- [ ] Verify NIP-17/NIP-28/NIP-46/NIP-59 alignment with latest NIP specs\n- [ ] Confirm kind number allocation doesn't conflict with existing Nostr ecosystem\n\n### 2. NostrConfig Type (`internal/config/types.go`)\n\nAdd new config types to the existing config package:\n\n```go\ntype NostrConfig struct {\n    Enabled        bool              `json:\"enabled\" yaml:\"enabled\"`\n    ReadRelays     []string          `json:\"read_relays\" yaml:\"read-relays\"`\n    WriteRelays    []string          `json:\"write_relays\" yaml:\"write-relays\"`\n    BlossomServers []string          `json:\"blossom_servers\" yaml:\"blossom-servers\"`\n    DMRelays       []string          `json:\"dm_relays\" yaml:\"dm-relays\"`\n    Identities     map[string]*NostrIdentity `json:\"identities\" yaml:\"identities\"`\n    Defaults       NostrDefaults     `json:\"defaults\" yaml:\"defaults\"`\n}\n\ntype NostrIdentity struct {\n    Pubkey  string        `json:\"pubkey\" yaml:\"pubkey\"`\n    Signer  SignerConfig  `json:\"signer\" yaml:\"signer\"`\n    Profile *AgentProfile `json:\"profile,omitempty\" yaml:\"profile,omitempty\"`\n}\n\ntype SignerConfig struct {\n    Type   string `json:\"type\" yaml:\"type\"`     // \"nip46\"\n    Bunker string `json:\"bunker\" yaml:\"bunker\"` // bunker://npub1...?relay=wss://...\n}\n\ntype AgentProfile struct {\n    Name        string `json:\"name\" yaml:\"name\"`\n    DisplayName string `json:\"display_name\" yaml:\"display-name\"`\n    About       string `json:\"about\" yaml:\"about\"`\n    Picture     string `json:\"picture\" yaml:\"picture\"`\n    Bot         bool   `json:\"bot\" yaml:\"bot\"`\n}\n\ntype NostrDefaults struct {\n    HeartbeatIntervalSec      int `json:\"heartbeat_interval_seconds\" yaml:\"heartbeat-interval-seconds\"`\n    SpoolDrainIntervalSec     int `json:\"spool_drain_interval_seconds\" yaml:\"spool-drain-interval-seconds\"`\n    ConvoyRecomputeIntervalSec int `json:\"convoy_recompute_interval_seconds\" yaml:\"convoy-recompute-interval-seconds\"`\n    IssueMirrorPollIntervalSec int `json:\"issue_mirror_poll_interval_seconds\" yaml:\"issue-mirror-poll-interval-seconds\"`\n}\n```\n\n### 3. Config Loader (`internal/config/loader.go`)\n\nExtend the existing loader to handle:\n\n- **Town-level config**: `~/gt/settings/nostr.json` (file permissions: 0600)\n- **Rig-level overrides**: `~/gt/<rig>/config.json` → `.nostr` section\n- **Merge strategy**: Rig overrides town defaults for relays and identities\n- **Validation**:\n  - At least one write relay when enabled\n  - Valid NIP-46 bunker URIs (parse `bunker://` scheme)\n  - Pubkeys are valid hex or npub format\n  - No nsec values anywhere (reject with clear error)\n\n### 4. Environment Variable Support (`internal/config/env.go`)\n\nExport/read these environment variables:\n\n```\nGT_NOSTR_ENABLED=1\nGT_NOSTR_READ_RELAYS=wss://relay1,wss://relay2\nGT_NOSTR_WRITE_RELAYS=wss://relay1\nGT_NOSTR_PUBKEY=npub1...\nGT_NOSTR_SIGNER_TYPE=nip46\nGT_NOSTR_BUNKER=bunker://...\nGT_NOSTR_HEARTBEAT_INTERVAL=60\nGT_NOSTR_BLOSSOM_SERVERS=https://blossom.example.com\n```\n\nPrecedence: env vars > rig config > town config > defaults\n\n### 5. Config File Template\n\nCreate a template/example config at `docs/examples/nostr-config.json` showing all options with comments.\n\n### 6. Feature Flag\n\n- `GT_NOSTR_ENABLED=1` activates Nostr publishing; default is off\n- All Nostr code paths must check this flag before executing\n- Add helper: `func IsNostrEnabled() bool` to config package\n\n## Files to Modify\n\n| File | Changes |\n|------|---------|\n| `internal/config/types.go` | Add NostrConfig, NostrIdentity, SignerConfig, AgentProfile, NostrDefaults structs |\n| `internal/config/loader.go` | Add LoadNostrConfig(), LoadNostrConfigForRig(), merge logic |\n| `internal/config/env.go` | Add GT_NOSTR_* env var reading |\n| `docs/design/nostr-protocol.md` | Final review annotations |\n| `docs/examples/nostr-config.json` | New — example config file |\n\n## Acceptance Criteria\n\n- [ ] `NostrConfig` struct compiles and has full YAML/JSON tags\n- [ ] `LoadNostrConfig()` reads `~/gt/settings/nostr.json`\n- [ ] Rig-level overrides merge correctly\n- [ ] Env vars override file config\n- [ ] Bunker URI validation rejects invalid formats\n- [ ] nsec detection: any config containing nsec is rejected with error\n- [ ] `IsNostrEnabled()` returns false by default, true with env/config\n- [ ] Unit tests for loader, validation, env precedence\n- [ ] Example config file created"}
{"action":"create","id":"gt-nostr-p2","title":"[P2] Nostr Publisher Package & Agent Identity","type":"task","priority":"critical","description":"# Phase 2: Nostr Publisher Package & Agent Identity System\n\n**Parent Epic**: gt-nostr-epic\n**Depends On**: gt-nostr-p1\n**Blocks**: gt-nostr-p3, gt-nostr-p4, gt-nostr-p5, gt-nostr-p6, gt-nostr-p7\n**Estimated Effort**: Large\n\n## Objective\n\nBuild the core `internal/nostr/` Go package that all publishing flows use, AND implement the per-agent identity provisioning system. This is the workhorse package — every subsequent phase calls into it.\n\n## Deliverables\n\n### 1. Package Structure (`internal/nostr/`)\n\n```\ninternal/nostr/\n├── client.go       # Relay connection manager (pool)\n├── event.go        # Event construction helpers + kind constants\n├── identity.go     # Per-agent keypair provisioning, profile publishing\n├── publisher.go    # High-level publish API (sign + broadcast + spool fallback)\n├── registry.go     # Identity registry (GT address → pubkey mapping)\n├── signer.go       # NIP-46 signer interface + bunker client\n├── spool.go        # Local event spool for offline resilience\n└── types.go        # Shared types, constants, tag builders\n```\n\n### 2. Event Types & Constants (`types.go`)\n\n```go\nconst (\n    KindLogStatus       = 30315\n    KindLifecycle       = 30316\n    KindConvoyState     = 30318\n    KindBeadsIssueState = 30319\n    KindProtocolEvent   = 30320\n    KindGroupDef        = 30321\n    KindQueueDef        = 30322\n    KindChannelDef      = 30323\n    KindWorkItem        = 30325\n    \n    // Standard Nostr kinds (reused)\n    KindProfile         = 0\n    KindChannelCreate   = 40\n    KindChannelMeta     = 41\n    KindChannelMessage  = 42\n    KindDirectMessage   = 14\n    KindGiftWrap        = 1059\n    KindRelayList       = 10002\n    KindDMRelayList     = 10050\n)\n\nconst ProtocolVersion = \"1\"\nconst SchemaPrefix    = \"gt/\"\n```\n\n### 3. Tag Builders (`types.go`)\n\nHelper functions for constructing the common tag schema:\n\n```go\nfunc BaseTags(rig, role, actor string) [][]string\nfunc CorrelationTags(issueID, convoyID, beadID, sessionID string) [][]string\nfunc ReplaceableTag(d string) []string\nfunc TypeTag(eventType string) []string\nfunc VisibilityTag(visibility string) []string\n```\n\n### 4. NIP-46 Signer (`signer.go`)\n\nInterface + implementation for signing events via external bunker:\n\n```go\ntype Signer interface {\n    // Sign adds id, pubkey, and sig to the event\n    Sign(event *nostr.Event) error\n    // GetPublicKey returns the signer's public key\n    GetPublicKey() string\n    // Close disconnects from bunker\n    Close() error\n}\n\ntype NIP46Signer struct {\n    bunkerURI string\n    pubkey    string\n    relay     *nostr.Relay\n    // ...\n}\n\nfunc NewNIP46Signer(bunkerURI string) (*NIP46Signer, error)\n```\n\nAlso implement a `LocalSigner` for development/testing:\n```go\ntype LocalSigner struct { privkey string }\nfunc NewLocalSigner(nsec string) *LocalSigner\n```\n\n### 5. Relay Client (`client.go`)\n\n```go\ntype RelayPool struct {\n    readRelays  []*nostr.Relay\n    writeRelays []*nostr.Relay\n}\n\nfunc NewRelayPool(cfg *config.NostrConfig) (*RelayPool, error)\nfunc (p *RelayPool) Publish(ctx context.Context, event nostr.Event) error\nfunc (p *RelayPool) Subscribe(ctx context.Context, filters []nostr.Filter) *nostr.Subscription\nfunc (p *RelayPool) Close()\n```\n\n- Auto-reconnect on disconnect\n- Connection health monitoring\n- Configurable timeouts\n\n### 6. Publisher (`publisher.go`)\n\nHigh-level API that handles sign → publish → spool-on-failure:\n\n```go\ntype Publisher struct {\n    signer Signer\n    pool   *RelayPool\n    spool  *Spool\n}\n\nfunc NewPublisher(cfg *config.NostrConfig) (*Publisher, error)\nfunc (p *Publisher) Publish(ctx context.Context, event *nostr.Event) error\nfunc (p *Publisher) PublishReplaceable(ctx context.Context, event *nostr.Event) error\nfunc (p *Publisher) Close() error\n```\n\nWorkflow:\n1. Sign event via NIP-46 signer\n2. Attempt broadcast to all write relays\n3. If ALL relays fail → spool event locally\n4. Return error only if spool also fails\n\n### 7. Spool (`spool.go`)\n\nLocal event store for offline resilience:\n\n```go\ntype Spool struct {\n    path          string  // ~/gt/.runtime/nostr-spool.jsonl\n    archivePath   string  // ~/gt/.runtime/nostr-spool-archive.jsonl\n    softLimit     int     // 10,000 events\n    hardLimit     int     // 100,000 events\n}\n\nfunc NewSpool(runtimeDir string) *Spool\nfunc (s *Spool) Enqueue(event *nostr.Event, targetRelays []string) error\nfunc (s *Spool) Drain(ctx context.Context, pool *RelayPool) (sent int, failed int, err error)\nfunc (s *Spool) Count() int\nfunc (s *Spool) ArchiveOld(maxAge time.Duration) (archived int, err error)\n```\n\nDrain strategy:\n- Deacon daemon calls Drain() every `spool_drain_interval_seconds` (default: 30s)\n- Exponential backoff on repeated failures (30s → 60s → 120s → 300s cap)\n- Events older than 24 hours → archive file\n- Soft limit (10k): log warning, drop audit-visibility events first\n- Hard limit (100k): stop spooling, log error, require operator intervention\n\nSpool file format:\n```json\n{\"id\":\"<event-id>\",\"created_at\":1707820800,\"kind\":30315,\"tags\":[...],\"content\":\"...\",\"sig\":\"...\",\"spool_meta\":{\"spooled_at\":\"2026-02-13T10:00:00Z\",\"target_relays\":[\"wss://relay.example.com\"],\"attempts\":0,\"last_attempt\":null,\"last_error\":null}}\n```\n\n### 8. Agent Identity Provisioning (`identity.go`)\n\nPer-agent keypair lifecycle managed by the Deacon via NIP-46:\n\n```go\ntype IdentityManager struct {\n    deaconSigner Signer\n    pool         *RelayPool\n    registry     *IdentityRegistry\n}\n\nfunc NewIdentityManager(cfg *config.NostrConfig) (*IdentityManager, error)\n\n// ProvisionAgent creates a keypair for a new agent\nfunc (im *IdentityManager) ProvisionAgent(actor, role, rig string) (*AgentIdentity, error)\n\n// PublishProfile publishes kind 0 profile for an agent\nfunc (im *IdentityManager) PublishProfile(agent *AgentIdentity) error\n\n// PublishRelayLists publishes kind 10002 + 10050 for an agent\nfunc (im *IdentityManager) PublishRelayLists(agent *AgentIdentity, readRelays, writeRelays, dmRelays []string) error\n\n// RetireAgent marks agent as retired, publishes final lifecycle event\nfunc (im *IdentityManager) RetireAgent(actor string) error\n```\n\nProvisioning flow:\n1. `gt spawn` triggers ProvisionAgent()\n2. Request keypair from NIP-46 bunker\n3. Store bunker URI in agent config (env var `GT_NOSTR_BUNKER`)\n4. Publish kind 0 profile (name, display_name, about, picture, `bot: true`)\n5. Publish kind 10002 relay list + kind 10050 DM relay list\n6. Register in identity registry\n\nAgent profile template (kind 0 content):\n```json\n{\n    \"name\": \"Toast\",\n    \"display_name\": \"Polecat Toast (gastown)\",\n    \"about\": \"Polecat worker on the gastown rig. Currently working on gt-123.\",\n    \"picture\": \"https://blossom.example.com/polecat-avatar.png\",\n    \"nip05\": \"toast@gastown.example.com\",\n    \"bot\": true\n}\n```\n\n### 9. Identity Registry (`registry.go`)\n\nMapping of Gas Town addresses → Nostr pubkeys:\n\n```go\ntype IdentityRegistry struct {\n    agents map[string]*RegisteredAgent  // key: actor address\n}\n\ntype RegisteredAgent struct {\n    Pubkey       string    `json:\"pubkey\"`\n    BunkerURI    string    `json:\"bunker\"`\n    Status       string    `json:\"status\"`  // active|retired\n    ProvisionedAt time.Time `json:\"provisioned_at\"`\n    Actor        string    `json:\"actor\"`\n    Role         string    `json:\"role\"`\n    Rig          string    `json:\"rig\"`\n}\n\nfunc NewIdentityRegistry(cfg *config.NostrConfig) *IdentityRegistry\nfunc (r *IdentityRegistry) Register(agent *RegisteredAgent) error\nfunc (r *IdentityRegistry) Lookup(actor string) (*RegisteredAgent, error)\nfunc (r *IdentityRegistry) LookupByPubkey(pubkey string) (*RegisteredAgent, error)\nfunc (r *IdentityRegistry) Publish(publisher *Publisher) error  // Publish as Nostr event\nfunc (r *IdentityRegistry) LoadFromRelay(pool *RelayPool) error  // Load from relay\n```\n\nThe registry is:\n- Stored locally in `~/gt/settings/identity-registry.json`\n- Published as a replaceable Nostr event (kind 30316 with `d=identity_registry`)\n- Loadable from relays by Flotilla for address → pubkey resolution\n\n## External Dependency\n\nAdd `fiatjaf.com/nostr` to `go.mod` (the canonical Go library for Nostr — `github.com/nbd-wtf/go-nostr` is deprecated):\n- Event types and serialization\n- Relay connections (WebSocket)\n- NIP-46 client support\n- Signature verification\n\nSee import mapping table in `docs/design/nostr-protocol.md` for the full old→new package path mapping.\n\n**Acceptance check**: `git grep github.com/nbd-wtf/go-nostr` returns zero results.\n\n## Files to Create\n\n| File | Purpose |\n|------|---------|\n| `internal/nostr/types.go` | Kind constants, schema prefix, tag builders |\n| `internal/nostr/signer.go` | Signer interface, NIP46Signer, LocalSigner |\n| `internal/nostr/client.go` | RelayPool with auto-reconnect |\n| `internal/nostr/publisher.go` | High-level publish with spool fallback |\n| `internal/nostr/spool.go` | Local event store, drain, archive |\n| `internal/nostr/event.go` | Event construction helpers per kind |\n| `internal/nostr/identity.go` | Agent keypair provisioning, profile publishing |\n| `internal/nostr/registry.go` | Identity registry (address → pubkey) |\n| `go.mod` | Add `fiatjaf.com/nostr` dependency |\n\n## Files to Modify\n\n| File | Changes |\n|------|---------|\n| `internal/config/types.go` | Ensure NostrConfig is referenced from TownSettings |\n| `internal/session/startup.go` | Pass bunker URI to spawned agents via env |\n\n## Acceptance Criteria\n\n- [ ] `fiatjaf.com/nostr` dependency added and compiling\n- [ ] No references to deprecated `github.com/nbd-wtf/go-nostr` anywhere\n- [ ] NIP-46 signer connects to bunker and signs events\n- [ ] LocalSigner works for testing without bunker\n- [ ] RelayPool connects to configured relays with auto-reconnect\n- [ ] Publisher signs + broadcasts events\n- [ ] Publisher spools events on relay failure\n- [ ] Spool drains with exponential backoff\n- [ ] Spool respects soft/hard limits\n- [ ] Spool archives old events (>24h)\n- [ ] IdentityManager provisions agent keypairs via NIP-46\n- [ ] Kind 0 profiles published for agents (with bot: true)\n- [ ] Kind 10002 + 10050 relay lists published\n- [ ] Identity registry stores GT address → pubkey mapping\n- [ ] Registry publishable as Nostr event\n- [ ] Registry loadable from relay\n- [ ] Tag builder helpers produce correct tag arrays\n- [ ] Event construction helpers produce valid Nostr events\n- [ ] Unit tests for all public APIs\n- [ ] Integration test: sign → publish → verify on local relay"}
{"action":"create","id":"gt-nostr-p3","title":"[P3] Dual-Write Activity Logs (30315)","type":"task","priority":"high","description":"# Phase 3: Dual-Write Activity Logs (Kind 30315 LOG_STATUS)\n\n**Parent Epic**: gt-nostr-epic\n**Depends On**: gt-nostr-p2\n**Blocks**: gt-nostr-p8, gt-nostr-p9\n**Estimated Effort**: Medium\n\n## Objective\n\nModify `internal/events/events.go` to dual-write: every event logged to `.events.jsonl` is ALSO published as a kind 30315 Nostr event when `GT_NOSTR_ENABLED=1`. This is the first concrete Nostr publishing integration.\n\n## Background\n\nThe events package currently:\n- Writes to `~/gt/.events.jsonl` (append-only, file-locked)\n- Has 20+ event types (sling, hook, done, mail, spawn, kill, etc.)\n- Each event has: Timestamp, Source, Type, Actor, Payload, Visibility\n- Visibility is `audit` (internal only), `feed` (shown to user), or `both`\n\n## Deliverables\n\n### 1. Event Construction Helpers (`internal/nostr/event.go`)\n\nCreate helpers that map every `events.Type*` constant to a kind 30315 event:\n\n```go\nfunc NewLogStatusEvent(eventType, actor, rig, role, visibility string, payload map[string]interface{}, correlations *Correlations) *nostr.Event\n```\n\nCorrelation struct:\n```go\ntype Correlations struct {\n    IssueID   string\n    ConvoyID  string\n    BeadID    string\n    SessionID string\n    Branch    string\n    MergeReq  string\n}\n```\n\nThe helper must:\n- Set `kind = 30315`\n- Add base tags: `[\"gt\",\"1\"]`, `[\"type\",eventType]`, `[\"rig\",rig]`, `[\"role\",role]`, `[\"actor\",actor]`, `[\"visibility\",visibility]`\n- Add correlation tags when non-empty\n- Set content to `{\"schema\":\"gt/log@1\",\"type\":eventType,\"source\":\"gt\",\"payload\":{...}}`\n\n### 2. Event Type → Tag Mapping\n\nEvery event type maps to specific additional tags:\n\n| Type | Extra Tags |\n|------|------------|\n| `sling` | `[\"t\",beadID]`, `[\"target\",target]` |\n| `hook` | `[\"t\",beadID]` |\n| `unhook` | `[\"t\",beadID]` |\n| `handoff` | `[\"session\",sessionID]` |\n| `done` | `[\"t\",beadID]`, `[\"branch\",branch]` |\n| `mail` | — |\n| `spawn` | — |\n| `kill` | — |\n| `nudge` | — |\n| `boot` | — |\n| `halt` | — |\n| `session_start` | `[\"session\",id]` |\n| `session_end` | `[\"session\",id]` |\n| `session_death` | `[\"session\",name]` |\n| `mass_death` | — |\n| `patrol_started` | — |\n| `polecat_checked` | — |\n| `polecat_nudged` | — |\n| `escalation_sent` | — |\n| `escalation_acked` | — |\n| `escalation_closed` | — |\n| `patrol_complete` | — |\n| `merge_started` | `[\"mr\",mrID]`, `[\"branch\",branch]` |\n| `merged` | `[\"mr\",mrID]`, `[\"branch\",branch]` |\n| `merge_failed` | `[\"mr\",mrID]`, `[\"branch\",branch]` |\n| `merge_skipped` | `[\"mr\",mrID]`, `[\"branch\",branch]` |\n\n### 3. Modify `events.go` Write Path\n\nUpdate the `write()` function:\n\n```go\nfunc write(event Event) error {\n    // Existing: write to .events.jsonl\n    if err := writeToFile(event); err != nil {\n        return err\n    }\n    \n    // New: publish to Nostr if enabled\n    if config.IsNostrEnabled() {\n        go publishToNostr(event)  // async, non-blocking\n    }\n    \n    return nil\n}\n```\n\nKey design decisions:\n- **Async publishing**: Nostr publish is fire-and-forget (goroutine), never blocks the caller\n- **Spool on failure**: If relay publish fails, the spool catches it\n- **No error propagation**: JSONL write is the source of truth; Nostr is best-effort during dual-write\n- **Actor → identity resolution**: Use the identity registry to resolve actor strings to Nostr pubkeys\n\n### 4. Payload Extraction for Tags\n\nThe tricky part: extracting correlation data from payload maps for tag construction. The payload helpers (SlingPayload, DonePayload, etc.) already build structured maps — we need to extract beadID, branch, etc. from them:\n\n```go\nfunc extractCorrelations(eventType string, payload map[string]interface{}) *Correlations {\n    c := &Correlations{}\n    switch eventType {\n    case TypeSling:\n        c.BeadID, _ = payload[\"bead\"].(string)\n        c.IssueID = c.BeadID  // bead ID is the issue ID\n    case TypeDone:\n        c.BeadID, _ = payload[\"bead\"].(string)\n        c.IssueID = c.BeadID\n        c.Branch, _ = payload[\"branch\"].(string)\n    // ... etc for all types\n    }\n    return c\n}\n```\n\n### 5. Spool Drain Integration\n\nIntegrate spool draining into the deacon daemon tick:\n\n```go\n// In internal/daemon/ or internal/deacon/\nfunc (d *Deacon) startSpoolDrain() {\n    ticker := time.NewTicker(d.cfg.Nostr.Defaults.SpoolDrainIntervalSec * time.Second)\n    for {\n        select {\n        case <-ticker.C:\n            sent, failed, err := d.spool.Drain(d.ctx, d.relayPool)\n            if err != nil {\n                log.Printf(\"spool drain error: %v\", err)\n            }\n            if sent > 0 {\n                log.Printf(\"spool: drained %d events (%d failed)\", sent, failed)\n            }\n        case <-d.ctx.Done():\n            return\n        }\n    }\n}\n```\n\n### 6. Publisher Singleton\n\nThe publisher should be a singleton initialized once at process startup:\n\n```go\nvar (\n    globalPublisher *nostr.Publisher\n    publisherOnce   sync.Once\n)\n\nfunc getPublisher() *nostr.Publisher {\n    publisherOnce.Do(func() {\n        cfg, _ := config.LoadNostrConfig()\n        globalPublisher, _ = nostr.NewPublisher(cfg)\n    })\n    return globalPublisher\n}\n```\n\n## Files to Modify\n\n| File | Changes |\n|------|---------|\n| `internal/events/events.go` | Add Nostr dual-write in `write()`, add `publishToNostr()`, add `extractCorrelations()` |\n| `internal/nostr/event.go` | Add `NewLogStatusEvent()` constructor |\n| `internal/nostr/types.go` | Add `Correlations` struct if not already there |\n\n## Files to Create\n\n| File | Purpose |\n|------|---------|\n| `internal/events/nostr.go` | Nostr-specific helpers, publisher singleton, correlation extraction |\n\n## Testing Strategy\n\n- Unit test: each event type produces correct tags and content\n- Unit test: correlation extraction for all 20+ event types\n- Integration test: write event → verify Nostr event on test relay\n- Integration test: write event with relay down → verify spool entry\n- Test: spool drain delivers spooled events\n- Test: async publish doesn't block caller even on slow relay\n\n## Acceptance Criteria\n\n- [ ] `GT_NOSTR_ENABLED=1` causes every `events.Log()` call to also publish kind 30315\n- [ ] All 20+ event types produce correct Nostr tags\n- [ ] Correlation tags (issue, convoy, session, branch, MR) populated from payload\n- [ ] Content JSON matches spec schema (`gt/log@1`)\n- [ ] Publishing is async and non-blocking\n- [ ] Relay failures are caught by spool\n- [ ] Spool drain runs in deacon daemon tick\n- [ ] Existing `.events.jsonl` writes continue unchanged\n- [ ] Publisher singleton initialized once per process\n- [ ] Unit tests for every event type mapping\n- [ ] Integration test with test relay"}
{"action":"create","id":"gt-nostr-p4","title":"[P4] Agent Lifecycle Signaling (30316)","type":"task","priority":"high","description":"# Phase 4: Agent Lifecycle Signaling (Kind 30316 LIFECYCLE)\n\n**Parent Epic**: gt-nostr-epic\n**Depends On**: gt-nostr-p2\n**Blocks**: gt-nostr-p8, gt-nostr-p9\n**Estimated Effort**: Medium\n\n## Objective\n\nPublish agent lifecycle events (register, heartbeat, retire, dead) as kind 30316 replaceable Nostr events, enabling UIs to show \"who is running\" and detect stale/dead agents without filesystem access.\n\n## Background\n\nCurrently, agent state is stored in `.runtime/*.json` files managed by `internal/agent/state.go`'s `StateManager`. The Deacon daemon reads these files to detect stale agents. This works locally but is invisible to remote UIs like Flotilla.\n\n## Deliverables\n\n### 1. Lifecycle Event Constructor (`internal/nostr/event.go`)\n\n```go\nfunc NewLifecycleEvent(actor, rig, role, instance, status string, content LifecycleContent) *nostr.Event\n```\n\nEvent structure:\n- Kind: 30316\n- Replaceable key `d`: `<rig>/<role>/<instance>` (e.g., `gastown/polecats/Toast`)\n- Tags: `[\"gt\",\"1\"]`, `[\"d\",key]`, `[\"rig\",rig]`, `[\"role\",role]`, `[\"actor\",actor]`, `[\"instance\",instanceID]`, `[\"status\",status]`\n- Optional tags: `[\"addr\",host]`, `[\"t\",currentIssue]`, `[\"model\",llmModel]`\n- Content: `{\"schema\":\"gt/lifecycle@1\",\"status\":\"ready\",\"role\":\"polecat\",...}`\n\n### 2. Lifecycle Content Type\n\n```go\ntype LifecycleContent struct {\n    Schema        string `json:\"schema\"`  // \"gt/lifecycle@1\"\n    Status        string `json:\"status\"`  // ready|busy|retiring|dead\n    Role          string `json:\"role\"`\n    Rig           string `json:\"rig\"`\n    Instance      string `json:\"instance\"`\n    CWD           string `json:\"cwd,omitempty\"`\n    StartedAt     string `json:\"started_at\"`\n    LastHeartbeat string `json:\"last_heartbeat\"`\n    CurrentIssue  string `json:\"current_issue,omitempty\"`\n    Model         string `json:\"model,omitempty\"`\n}\n```\n\n### 3. Lifecycle State Machine\n\n```\n           ┌─────────┐\n           │  ready   │◀──── heartbeat (periodic)\n           └────┬─────┘\n                │ work assigned\n                ▼\n           ┌─────────┐\n           │  busy    │◀──── heartbeat (periodic, with issue tag)\n           └────┬─────┘\n                │ work complete / session ending\n                ▼\n           ┌──────────┐\n           │ retiring  │───── graceful shutdown\n           └────┬──────┘\n                │\n                ▼\n           ┌─────────┐\n           │  dead    │───── terminal (Deacon publishes on crash detection)\n           └─────────┘\n```\n\n### 4. Heartbeat Integration\n\nModify the existing heartbeat mechanism to also publish kind 30316:\n\n**Agent-side heartbeat** (every 60s, configurable via `GT_NOSTR_HEARTBEAT_INTERVAL`):\n```go\nfunc (a *Agent) publishHeartbeat() {\n    if !config.IsNostrEnabled() { return }\n    \n    status := \"ready\"\n    if a.currentIssue != \"\" {\n        status = \"busy\"\n    }\n    \n    event := nostr.NewLifecycleEvent(\n        a.actor, a.rig, a.role, a.instance, status,\n        nostr.LifecycleContent{\n            Schema:        \"gt/lifecycle@1\",\n            Status:        status,\n            Role:          a.role,\n            Rig:           a.rig,\n            Instance:      a.instance,\n            CWD:           a.cwd,\n            StartedAt:     a.startedAt.Format(time.RFC3339),\n            LastHeartbeat: time.Now().Format(time.RFC3339),\n            CurrentIssue:  a.currentIssue,\n            Model:         a.model,\n        },\n    )\n    \n    publisher.PublishReplaceable(ctx, event)\n}\n```\n\n**Deacon heartbeat** (every 30s — supervisor is more critical):\n- Same pattern but with `role=deacon`\n- Also publishes `dead` status for agents that miss 3× heartbeat intervals\n\n### 5. Session Spawn Integration (`internal/session/startup.go`)\n\nWhen a new session spawns:\n1. Publish kind 30316 with `status=ready`\n2. Start heartbeat goroutine\n3. On graceful exit → publish `status=retiring`, then `status=dead`\n4. On crash → Deacon detects missing heartbeats, publishes `status=dead`\n\n### 6. Crash Detection & Death Publishing\n\nThe Deacon already detects stale/dead agents. Add Nostr publishing:\n\n```go\nfunc (d *Deacon) markAgentDead(actor, reason string) {\n    // Existing: update .runtime state\n    d.stateManager.MarkDead(actor)\n    \n    // New: publish authoritative death event\n    if config.IsNostrEnabled() {\n        event := nostr.NewLifecycleEvent(\n            actor, ..., \"dead\",\n            nostr.LifecycleContent{\n                Status: \"dead\",\n                // ...\n            },\n        )\n        d.publisher.PublishReplaceable(ctx, event)\n    }\n}\n```\n\n### 7. Stale Threshold\n\n- Agent heartbeat: every 60s → stale after 180s (3×)\n- Deacon heartbeat: every 30s → stale after 90s (3×)\n- Flotilla UI shows \"stale\" indicator after threshold\n- Deacon publishes `dead` after stale threshold for non-Deacon agents\n\n### 8. Dual-Write: Local `.runtime` Continues\n\nThe existing `StateManager` in `agent/state.go` continues to persist state locally. Nostr events are published IN ADDITION TO local state, not instead of. Local state acts as cache for when relays are unreachable.\n\n## Files to Modify\n\n| File | Changes |\n|------|---------|\n| `internal/agent/state.go` | Add Nostr publish on state transitions |\n| `internal/session/startup.go` | Publish lifecycle on spawn, start heartbeat |\n| `internal/deacon/` (daemon tick) | Publish dead transitions, deacon heartbeat |\n| `internal/nostr/event.go` | Add `NewLifecycleEvent()` constructor |\n| `internal/nostr/types.go` | Add `LifecycleContent` type |\n\n## Files to Create\n\n| File | Purpose |\n|------|---------|\n| `internal/nostr/lifecycle.go` | Heartbeat goroutine, lifecycle publishing helpers |\n\n## Acceptance Criteria\n\n- [ ] Kind 30316 published on agent spawn (status=ready)\n- [ ] Heartbeat published every 60s (agent) / 30s (deacon)\n- [ ] Status transitions (ready→busy→retiring→dead) published correctly\n- [ ] Replaceable key `d` is stable across heartbeats (same key = same agent)\n- [ ] Current issue tag added when agent is busy\n- [ ] Deacon publishes authoritative `dead` for crashed agents\n- [ ] Local `.runtime` state files continue to work unchanged\n- [ ] Stale detection threshold: 3× heartbeat interval\n- [ ] Heartbeat interval configurable via `GT_NOSTR_HEARTBEAT_INTERVAL`\n- [ ] Unit tests for lifecycle event construction\n- [ ] Integration test: spawn → heartbeat → retire lifecycle"}
{"action":"create","id":"gt-nostr-p5","title":"[P5] Convoy State & Issue Mirrors (30318 + 30319)","type":"task","priority":"high","description":"# Phase 5: Convoy State & Beads Issue Mirrors (Kinds 30318 + 30319)\n\n**Parent Epic**: gt-nostr-epic\n**Depends On**: gt-nostr-p2\n**Blocks**: gt-nostr-p8, gt-nostr-p9\n**Estimated Effort**: Large\n\n## Objective\n\nPublish convoy progress and beads issue state as replaceable Nostr events, eliminating the need for `bd dep list` / `gt convoy check` shell-outs and enabling Flotilla to render issues without filesystem access.\n\n## Deliverables\n\n### 1. Convoy State Events (Kind 30318)\n\n#### Event Constructor\n\n```go\nfunc NewConvoyStateEvent(convoyID string, content ConvoyStateContent) *nostr.Event\n```\n\nEvent structure:\n- Kind: 30318\n- Replaceable key `d`: `<convoy-id>` (e.g., `hq-cv-abc`)\n- Tags: `[\"gt\",\"1\"]`, `[\"d\",convoyID]`, `[\"status\",status]`, plus `[\"t\",issueID]` for each tracked issue, `[\"notify\",actor]` for notification targets\n- Content: Full convoy state JSON\n\n#### Content Schema\n\n```go\ntype ConvoyStateContent struct {\n    Schema        string                `json:\"schema\"` // \"gt/convoy_state@1\"\n    ID            string                `json:\"id\"`\n    Title         string                `json:\"title\"`\n    Status        string                `json:\"status\"` // open|landed|cancelled\n    CreatedAt     string                `json:\"created_at\"`\n    CreatedBy     string                `json:\"created_by\"`\n    TrackedIssues []ConvoyTrackedIssue  `json:\"tracked_issues\"`\n    Summary       ConvoySummary         `json:\"summary\"`\n    ActiveWorkers []string              `json:\"active_workers\"`\n    Landed        bool                  `json:\"landed\"`\n    LandedAt      *string               `json:\"landed_at\"`\n    LastUpdated   string                `json:\"last_updated\"`\n}\n\ntype ConvoyTrackedIssue struct {\n    ID       string `json:\"id\"`\n    Title    string `json:\"title\"`\n    Status   string `json:\"status\"`\n    Assignee string `json:\"assignee\"`\n    Rig      string `json:\"rig\"`\n}\n\ntype ConvoySummary struct {\n    Total   int `json:\"total\"`\n    Open    int `json:\"open\"`\n    Closed  int `json:\"closed\"`\n    Blocked int `json:\"blocked\"`\n}\n```\n\n#### Update Triggers\n\nThe Deacon recomputes and publishes 30318 when:\n1. A tracked issue's status changes (detected via 30319 issue mirror events)\n2. A `gt convoy check` is explicitly invoked\n3. A `38384` control event with `cmd=convoy_refresh` is received\n4. Periodic recomputation every `convoy_recompute_interval_seconds` (default: 300s / 5 min)\n\n#### Modify `internal/convoy/observer.go`\n\nReplace shell-outs with a hybrid approach:\n- **During dual-write**: Continue existing `bd dep list` calls BUT also publish 30318 after each check\n- **After Phase 9**: Replace `bd dep list` calls with Nostr subscription to 30319 events\n\n```go\nfunc CheckConvoysForIssue(townRoot, issueID, observer string, logger ...) []string {\n    // Existing logic...\n    convoys := getTrackingConvoys(townRoot, issueID)\n    \n    for _, convoy := range convoys {\n        runConvoyCheck(townRoot, convoy)\n        \n        // NEW: Publish convoy state to Nostr\n        if config.IsNostrEnabled() {\n            publishConvoyState(townRoot, convoy)\n        }\n    }\n    \n    return convoys\n}\n```\n\n### 2. Beads Issue Mirror Events (Kind 30319)\n\n#### Event Constructor\n\n```go\nfunc NewBeadsIssueStateEvent(issueID, rig string, content BeadsIssueContent) *nostr.Event\n```\n\nEvent structure:\n- Kind: 30319\n- Replaceable key `d`: `<issue-id>` (e.g., `gt-abc`)\n- Tags: `[\"gt\",\"1\"]`, `[\"d\",issueID]`, `[\"rig\",rig]`, `[\"status\",status]`, `[\"type\",issueType]`, `[\"priority\",priority]`\n- Optional tags: `[\"assignee\",actor]`, `[\"parent\",parentID]`, `[\"label\",label]` (repeated), `[\"convoy\",convoyID]`\n- Content: Full issue state with dependency graph\n\n#### Content Schema\n\n```go\ntype BeadsIssueContent struct {\n    Schema       string            `json:\"schema\"` // \"gt/beads_issue_state@1\"\n    ID           string            `json:\"id\"`\n    Title        string            `json:\"title\"`\n    Status       string            `json:\"status\"`\n    Priority     string            `json:\"priority\"`\n    Type         string            `json:\"type\"`\n    CreatedAt    string            `json:\"created_at\"`\n    CreatedBy    string            `json:\"created_by\"`\n    UpdatedAt    string            `json:\"updated_at\"`\n    Assignee     string            `json:\"assignee,omitempty\"`\n    Labels       []string          `json:\"labels\"`\n    Rig          string            `json:\"rig\"`\n    Dependencies IssueDependencies `json:\"dependencies\"`\n    Branch       string            `json:\"branch,omitempty\"`\n    Molecule     *MoleculeState    `json:\"molecule,omitempty\"`\n    Blobs        []BlobReference   `json:\"blobs,omitempty\"`\n    Source       *IssueSource      `json:\"source,omitempty\"`\n}\n\ntype IssueDependencies struct {\n    BlockedBy []string `json:\"blocked_by\"`\n    Blocks    []string `json:\"blocks\"`\n    Children  []string `json:\"children\"`\n    Parent    *string  `json:\"parent\"`\n}\n\ntype MoleculeState struct {\n    ID             string `json:\"id\"`\n    Status         string `json:\"status\"`\n    WispCount      int    `json:\"wisp_count\"`\n    WispsCompleted int    `json:\"wisps_completed\"`\n}\n\ntype BlobReference struct {\n    Type   string `json:\"type\"`   // patch, diff, screenshot, log\n    URL    string `json:\"url\"`    // Blossom URL\n    SHA256 string `json:\"sha256\"`\n    Size   int    `json:\"size\"`\n}\n\ntype IssueSource struct {\n    Repo       string  `json:\"repo\"`\n    NIP34Event *string `json:\"nip34_event\"`\n}\n```\n\n#### Blossom Blob Offloading\n\nWhen issue state includes large artifacts:\n1. Upload blob to configured Blossom server(s) using PUT with SHA-256 hash\n2. Include `blobs[]` array in event content with `url`, `sha256`, `size`\n3. Consumers fetch blobs on-demand\n4. Blossom URLs are content-addressed (stable by hash)\n\n```go\ntype BlobUploader struct {\n    servers []string  // Blossom server URLs\n}\n\nfunc (u *BlobUploader) Upload(data []byte, contentType string) (*BlobReference, error)\n```\n\n#### Mirror Update Triggers\n\n1. **In-process hooks**: When `internal/beads/beads.go` wrapper performs CRUD (Create, Update, Close, AddDependency, etc.), publish 30319\n2. **Background poll**: Deacon periodically runs `bd list --json` and diffs against last-known state (catch-all for changes made outside the wrapper)\n3. **Nostrig import**: When `nostrig fetch` imports NIP-34 repo events into beads, publish corresponding 30319 mirrors\n\n#### Modify `internal/beads/beads.go`\n\nAdd Nostr hooks to CRUD operations:\n\n```go\nfunc (b *Beads) Create(opts CreateOptions) (*Issue, error) {\n    issue, err := b.createViaBeads(opts)\n    if err != nil { return nil, err }\n    \n    // Mirror to Nostr\n    if config.IsNostrEnabled() {\n        go b.publishIssueMirror(issue)\n    }\n    \n    return issue, nil\n}\n\nfunc (b *Beads) Update(id string, opts UpdateOptions) error {\n    if err := b.updateViaBeads(id, opts); err != nil { return err }\n    \n    // Re-mirror to Nostr\n    if config.IsNostrEnabled() {\n        go func() {\n            issue, _ := b.Show(id)\n            if issue != nil {\n                b.publishIssueMirror(issue)\n            }\n        }()\n    }\n    \n    return nil\n}\n```\n\n### 3. Issue → Nostr Conversion\n\nMap `beads.Issue` struct to `BeadsIssueContent`:\n\n```go\nfunc issueToNostrContent(issue *beads.Issue, rig string) BeadsIssueContent {\n    return BeadsIssueContent{\n        Schema:   \"gt/beads_issue_state@1\",\n        ID:       issue.ID,\n        Title:    issue.Title,\n        Status:   issue.Status,\n        Priority: issue.Priority,\n        Type:     issue.Type,\n        // ... map all fields\n        Dependencies: IssueDependencies{\n            BlockedBy: issue.BlockedBy,\n            Blocks:    issue.Blocks,\n            Children:  issue.Children,\n            Parent:    issue.Parent,\n        },\n    }\n}\n```\n\n### 4. Background Poll Daemon\n\nDeacon periodically polls for issue changes:\n\n```go\nfunc (d *Deacon) startIssueMirrorPoll() {\n    interval := d.cfg.Nostr.Defaults.IssueMirrorPollIntervalSec\n    ticker := time.NewTicker(time.Duration(interval) * time.Second)\n    \n    var lastSnapshot map[string]string  // id → hash(content)\n    \n    for {\n        select {\n        case <-ticker.C:\n            issues, _ := d.beads.List(beads.ListOptions{})\n            for _, issue := range issues {\n                hash := hashIssue(issue)\n                if lastSnapshot[issue.ID] != hash {\n                    d.publishIssueMirror(issue)\n                    lastSnapshot[issue.ID] = hash\n                }\n            }\n        case <-d.ctx.Done():\n            return\n        }\n    }\n}\n```\n\n### 5. Nostrig Integration Hook\n\nWhen nostrig imports NIP-34 events into beads:\n```go\n// After nostrig import completes\nfunc onNostrigImport(importedIssueIDs []string) {\n    for _, id := range importedIssueIDs {\n        issue, _ := beads.Show(id)\n        if issue != nil {\n            publishIssueMirror(issue)\n        }\n    }\n}\n```\n\n## Files to Modify\n\n| File | Changes |\n|------|---------|\n| `internal/convoy/observer.go` | Add Nostr publish after convoy check |\n| `internal/beads/beads.go` | Add Nostr hooks to Create, Update, Close, AddDependency, RemoveDependency |\n| `internal/nostr/event.go` | Add `NewConvoyStateEvent()`, `NewBeadsIssueStateEvent()` constructors |\n| `internal/nostr/types.go` | Add content types for convoy and issue state |\n\n## Files to Create\n\n| File | Purpose |\n|------|---------|\n| `internal/nostr/convoy.go` | Convoy state computation and publishing |\n| `internal/nostr/issues.go` | Issue mirror computation, diff detection, Blossom upload |\n| `internal/nostr/blossom.go` | Blossom blob upload client |\n\n## Acceptance Criteria\n\n- [ ] Kind 30318 published for convoy state changes\n- [ ] Convoy state includes full tracked issue list with statuses\n- [ ] Convoy updates triggered by: issue status change, explicit check, control event, periodic recompute\n- [ ] Kind 30319 published for all beads issues\n- [ ] Issue mirrors include full dependency graph (blocked_by, blocks, children, parent)\n- [ ] Issue mirrors update on Create, Update, Close, AddDep, RemoveDep\n- [ ] Background poll catches changes made outside wrapper\n- [ ] Blossom blob upload for large artifacts (patches, diffs)\n- [ ] BlobReference includes URL, SHA-256, size\n- [ ] Nostrig import triggers issue mirror publish\n- [ ] Replaceable events use stable `d` tags (same issue = same key)\n- [ ] Unit tests for convoy and issue event construction\n- [ ] Integration test: create issue → verify 30319 on relay\n- [ ] Integration test: update convoy → verify 30318 on relay"}
{"action":"create","id":"gt-nostr-p6","title":"[P6] Protocol Events & Work Queues (30320 + 30325)","type":"task","priority":"high","description":"# Phase 6: Protocol Events & Work Queues (Kinds 30320, 30325, 30321-30323)\n\n**Parent Epic**: gt-nostr-epic\n**Depends On**: gt-nostr-p2\n**Blocks**: gt-nostr-p8, gt-nostr-p9\n**Estimated Effort**: Large\n\n## Objective\n\nReplace beads-native machine-to-machine mail with Nostr protocol events (30320), beads-native queue messages with claimable Nostr work items (30325), and publish group/queue/channel definitions (30321-30323).\n\n## Background\n\nThe current mail system (`internal/mail/`) uses beads issues as a transport layer:\n- Messages are beads issues with specific labels (`msg-type:`, `msg-thread:`, `msg-cc:`, etc.)\n- Queues are beads issues with `queue:` labels and claim semantics\n- Channels are beads announce lists\n- Groups are beads issues with member lists\n\nThis phase replaces the **machine-to-machine** subset with Nostr events. Conversational messaging (human ↔ agent) moves to NIP-17/NIP-28 in Phase 7.\n\n## Deliverables\n\n### 1. Protocol Events (Kind 30320 — GT_PROTOCOL_EVENT)\n\n#### Event Constructor\n\n```go\nfunc NewProtocolEvent(msgType, from, to, rig string, body map[string]interface{}, correlations *Correlations) *nostr.Event\n```\n\nEvent structure:\n- Kind: 30320\n- Tags: `[\"gt\",\"1\"]`, `[\"msg_type\",msgType]`, `[\"from\",from]`, `[\"to\",to]`, `[\"rig\",rig]`\n- Optional correlation tags: `[\"t\",issueID]`, `[\"branch\",branch]`, `[\"mr\",mrID]`, `[\"polecat\",name]`, `[\"convoy\",convoyID]`\n- Content: `{\"schema\":\"gt/protocol@1\",\"msg_type\":\"MERGE_READY\",\"body\":{...}}`\n\n#### Protocol Event Types\n\n| `msg_type` | Route | Key Body Fields |\n|------------|-------|-----------------|\n| `POLECAT_DONE` | Polecat → Witness | `exit`, `issue`, `mr?`, `branch` |\n| `MERGE_READY` | Witness → Refinery | `branch`, `issue`, `polecat`, `verified` |\n| `MERGED` | Refinery → Witness | `branch`, `issue`, `polecat`, `rig`, `target`, `merged_at`, `merge_commit` |\n| `MERGE_FAILED` | Refinery → Witness | `branch`, `issue`, `polecat`, `rig`, `target`, `failed_at`, `failure_type`, `error` |\n| `REWORK_REQUEST` | Refinery → Witness | `branch`, `issue`, `polecat`, `rig`, `target`, `requested_at`, `conflict_files[]` |\n| `HELP` | Any → Mayor | `agent`, `issue?`, `problem`, `tried` |\n\n#### Migration from Mail Router\n\nIdentify all `mail.Router.Send()` calls that send protocol messages and replace with Nostr publish:\n\n```go\n// Before:\nrouter.Send(&mail.Message{\n    From: \"gastown/polecats/Toast\",\n    To:   \"gastown/witness\",\n    Subject: \"POLECAT_DONE\",\n    Body: \"{\\\"exit\\\":\\\"MERGED\\\",...}\",\n})\n\n// After:\npublisher.Publish(ctx, nostr.NewProtocolEvent(\n    \"POLECAT_DONE\",\n    \"gastown/polecats/Toast\",\n    \"gastown/witness\",\n    \"gastown\",\n    map[string]interface{}{\"exit\": \"MERGED\", ...},\n    &nostr.Correlations{IssueID: \"gt-123\", Branch: \"feature/auth\"},\n))\n```\n\n#### Protocol Event Consumption\n\nAgents subscribe to protocol events addressed to them:\n\n```go\n// Witness subscribes to protocol events\nfilter := nostr.Filter{\n    Kinds: []int{30320},\n    Tags:  nostr.TagMap{\"gt\": []string{\"1\"}, \"to\": []string{\"gastown/witness\"}},\n}\n\npool.Subscribe(ctx, []nostr.Filter{filter})\n```\n\nProcess in the agent's existing patrol loop — these are NOT chat messages, they're machine-to-machine commands.\n\n### 2. Work Items (Kind 30325 — GT_WORK_ITEM)\n\n#### Event Constructor\n\n```go\nfunc NewWorkItemEvent(queue, from, rig, subject string, body map[string]interface{}) *nostr.Event\n```\n\nEvent structure:\n- Kind: 30325\n- Tags: `[\"gt\",\"1\"]`, `[\"queue\",queueName]`, `[\"from\",from]`, `[\"status\",\"available\"]`, `[\"rig\",rig]`\n- Optional: `[\"priority\",priority]`, `[\"t\",issueID]`\n- Content: `{\"schema\":\"gt/work_item@1\",\"queue\":\"merge-queue\",\"subject\":\"...\",\"body\":{...}}`\n\n#### Claim Semantics\n\nWorkers claim items by publishing a NEW 30325 event with:\n- Same content but `status=claimed`\n- `[\"claimed_by\",actor]` tag added\n- `[\"e\",originalEventID]` referencing the original work item\n\n```go\nfunc ClaimWorkItem(original *nostr.Event, claimedBy string) *nostr.Event\nfunc CompleteWorkItem(original *nostr.Event, claimedBy string) *nostr.Event\nfunc FailWorkItem(original *nostr.Event, claimedBy, reason string) *nostr.Event\n```\n\n#### Migration from Queue Messages\n\nReplace `mail.NewQueueMessage()` calls:\n\n```go\n// Before:\nrouter.Send(mail.NewQueueMessage(\n    \"gastown/witness\", \"merge-queue\", \"Merge feature/auth\", body,\n))\n\n// After:\npublisher.Publish(ctx, nostr.NewWorkItemEvent(\n    \"merge-queue\", \"gastown/witness\", \"gastown\", \"Merge feature/auth\", bodyMap,\n))\n```\n\n### 3. Group Definitions (Kind 30321 — GT_GROUP_DEF)\n\n```go\nfunc NewGroupDefEvent(groupName string, members []string, createdBy string) *nostr.Event\n```\n\n- Replaceable key `d`: group name\n- Tags: `[\"gt\",\"1\"]`, `[\"d\",name]`, `[\"status\",\"active\"]`, `[\"member\",addr]` (repeated)\n- Content: `{\"schema\":\"gt/group_def@1\",\"name\":\"...\",\"members\":[...],...}`\n\n### 4. Queue Definitions (Kind 30322 — GT_QUEUE_DEF)\n\n```go\nfunc NewQueueDefEvent(queueName, status, scope, rig string, maxConcurrency int) *nostr.Event\n```\n\n- Replaceable key `d`: queue name\n- Tags: `[\"gt\",\"1\"]`, `[\"d\",name]`, `[\"status\",status]`, `[\"scope\",scope]`\n- Content: `{\"schema\":\"gt/queue_def@1\",\"name\":\"...\",\"max_concurrency\":1,\"processing_order\":\"fifo\",...}`\n\n### 5. Channel Definitions (Kind 30323 — GT_CHANNEL_DEF)\n\n```go\nfunc NewChannelDefEvent(channelName string, subscribers []string, retention *RetentionConfig) *nostr.Event\n```\n\n- Replaceable key `d`: channel name\n- Tags: `[\"gt\",\"1\"]`, `[\"d\",name]`, `[\"status\",\"active\"]`, `[\"subscriber\",addr]` (repeated)\n- Content: `{\"schema\":\"gt/channel_def@1\",\"name\":\"...\",\"retention\":{\"count\":100},...}`\n\n### 6. Protocol Event → Patrol Loop Integration\n\nModify agent patrol loops to consume Nostr protocol events:\n\n```go\n// In Witness patrol loop\nfunc (w *Witness) processProtocolEvents() {\n    sub := w.pool.Subscribe(ctx, []nostr.Filter{{\n        Kinds: []int{30320},\n        Tags:  nostr.TagMap{\"gt\": []string{\"1\"}, \"to\": []string{w.actor}},\n        Since: &w.lastProcessed,\n    }})\n    \n    for event := range sub.Events {\n        msgType := event.Tags.GetFirst([]string{\"msg_type\"}).Value()\n        switch msgType {\n        case \"POLECAT_DONE\":\n            w.handlePolecatDone(event)\n        case \"MERGED\":\n            w.handleMerged(event)\n        case \"MERGE_FAILED\":\n            w.handleMergeFailed(event)\n        }\n    }\n}\n```\n\n## Dual-Write Strategy\n\nDuring the transition:\n1. Protocol events are published to BOTH beads mail AND Nostr\n2. Consuming agents check BOTH beads mailbox AND Nostr subscription\n3. Deduplication: track processed event IDs to avoid double-processing\n4. Phase 9 sunsets the beads mail path\n\n## Files to Modify\n\n| File | Changes |\n|------|---------|\n| `internal/mail/router.go` | Add Nostr dual-write for protocol messages, queue messages |\n| `internal/mail/types.go` | Add helper to detect protocol vs conversational messages |\n| `internal/witness/` | Add Nostr protocol event subscription in patrol loop |\n| `internal/refinery/` | Add Nostr protocol event subscription for MERGE_READY |\n| `internal/mayor/` | Add Nostr HELP event subscription |\n| `internal/nostr/event.go` | Add constructors for 30320, 30325, 30321, 30322, 30323 |\n| `internal/nostr/types.go` | Add content types for protocol, work item, group, queue, channel |\n\n## Files to Create\n\n| File | Purpose |\n|------|---------|\n| `internal/nostr/protocol.go` | Protocol event helpers, consumption router |\n| `internal/nostr/workqueue.go` | Work item helpers, claim/complete/fail |\n| `internal/nostr/definitions.go` | Group, queue, channel definition helpers |\n\n## Acceptance Criteria\n\n- [ ] Kind 30320 published for all machine-to-machine protocol events\n- [ ] All 6 protocol types (POLECAT_DONE, MERGE_READY, MERGED, MERGE_FAILED, REWORK_REQUEST, HELP) mapped\n- [ ] Protocol events consumed in agent patrol loops (Witness, Refinery, Mayor)\n- [ ] Kind 30325 work items replace queue messages\n- [ ] Work item claim semantics working (available → claimed → completed/failed)\n- [ ] Kind 30321 group definitions published\n- [ ] Kind 30322 queue definitions published\n- [ ] Kind 30323 channel definitions published\n- [ ] Dual-write: beads mail AND Nostr during transition\n- [ ] Deduplication of dual-read (don't process same event twice)\n- [ ] Mail router detects protocol vs conversational messages\n- [ ] Unit tests for all event constructors\n- [ ] Integration test: send protocol event → consumed by agent"}
{"action":"create","id":"gt-nostr-p7","title":"[P7] Chat & Channel Integration (NIP-17 + NIP-28)","type":"task","priority":"high","description":"# Phase 7: Chat & Channel Integration (NIP-17 DMs + NIP-28 Channels)\n\n**Parent Epic**: gt-nostr-epic\n**Depends On**: gt-nostr-p2\n**Blocks**: gt-nostr-p8\n**Estimated Effort**: Large\n\n## Objective\n\nImplement the conversational messaging layer: NIP-17 encrypted DMs for human ↔ agent interaction, and NIP-28 public channels for rig/town-wide discussion. This is what makes the Flotilla Discord-like experience possible.\n\n## Background\n\nFlotilla already has full support for:\n- **NIP-17 DMs**: `Chat.svelte`, `ChatCompose.svelte`, `sendWrapped()` — the entire DM pipeline\n- **NIP-28 Channels**: `ChannelMessage.svelte`, `channelEvents`, channel creation/metadata\n\nGas Town needs to:\n1. Create channels on `gt init` and `gt rig add`\n2. Give agents the ability to send/receive DMs and channel messages\n3. Implement a command router for DM-based agent control\n4. Route channel `@mentions` to the appropriate agent\n\n## Deliverables\n\n### 1. Channel Creation on Init/Rig Add\n\nWhen `gt init` runs, create town-level NIP-28 channels:\n\n| Channel | Kind 40 `name` | Purpose |\n|---------|----------------|---------|\n| `#town-ops` | `town-ops` | Cross-rig coordination, Mayor commands |\n| `#activity` | `activity` | Real-time feed of 30315 LOG_STATUS events (read-only, bot-posted) |\n| `#alerts` | `alerts` | Urgent escalations (HELP, mass_death, stale agents) |\n| `#announcements` | `announcements` | Announcements from overseer/mayor |\n\nWhen `gt rig add <rig>` runs, create per-rig channels:\n\n| Channel | Kind 40 `name` | Purpose |\n|---------|----------------|---------|\n| `#<rig>-dev` | `<rig>-dev` | Development discussion |\n| `#<rig>-merge` | `<rig>-merge` | Merge queue status |\n| `#<rig>-patrol` | `<rig>-patrol` | Witness patrol summaries |\n\nChannel creation event:\n```json\n{\n    \"kind\": 40,\n    \"content\": \"{\\\"name\\\":\\\"gastown-dev\\\",\\\"about\\\":\\\"Development channel for the gastown rig.\\\",\\\"picture\\\":\\\"...\\\"}\",\n    \"tags\": [[\"gt\",\"1\"],[\"rig\",\"gastown\"],[\"channel_type\",\"rig-dev\"]]\n}\n```\n\n### 2. Agent Auto-Subscribe on Spawn\n\nWhen an agent spawns, subscribe to channels based on role:\n\n| Role | Auto-Subscribe |\n|------|---------------|\n| Mayor | `#town-ops`, `#alerts`, `#announcements`, all `#<rig>-dev` |\n| Deacon | `#town-ops`, `#alerts`, `#activity` (publisher), all `#<rig>-patrol` |\n| Witness | `#<rig>-dev`, `#<rig>-merge`, `#<rig>-patrol`, `#alerts` |\n| Refinery | `#<rig>-dev`, `#<rig>-merge` |\n| Polecat | `#<rig>-dev` |\n| Crew | `#<rig>-dev`, `#announcements` |\n\nImplementation:\n```go\nfunc (a *Agent) subscribeToChannels() {\n    channelIDs := getChannelsForRole(a.role, a.rig)\n    for _, channelID := range channelIDs {\n        a.pool.Subscribe(ctx, []nostr.Filter{{\n            Kinds: []int{42},\n            Tags:  nostr.TagMap{\"e\": []string{channelID}},\n            Since: &now,\n        }})\n    }\n}\n```\n\n### 3. NIP-17 DM Send/Receive\n\nImplement NIP-17 gift-wrapped DM sending and receiving in Go:\n\n#### Sending DMs\n\n```go\nfunc (a *Agent) SendDM(recipientPubkey, content string, tags [][]string) error {\n    // 1. Create kind 14 unsigned event (the actual message)\n    rumor := &nostr.Event{\n        Kind:      14,\n        Content:   content,\n        Tags:      append(tags, []string{\"p\", recipientPubkey}),\n        CreatedAt: nostr.Timestamp(time.Now().Unix()),\n    }\n    \n    // 2. Create kind 13 seal (NIP-44 encrypted)\n    seal := nip17.Seal(rumor, a.signer, recipientPubkey)\n    \n    // 3. Create kind 1059 gift wrap (random key)\n    wrap := nip59.GiftWrap(seal, recipientPubkey)\n    \n    // 4. Publish to recipient's 10050 DM relays\n    return a.publishToDMRelays(wrap, recipientPubkey)\n}\n```\n\n#### Receiving DMs\n\n```go\nfunc (a *Agent) startDMListener() {\n    // Subscribe to gift wraps addressed to this agent\n    sub := a.pool.Subscribe(ctx, []nostr.Filter{{\n        Kinds: []int{1059},\n        Tags:  nostr.TagMap{\"p\": []string{a.pubkey}},\n        Since: &now,\n    }})\n    \n    for wrap := range sub.Events {\n        // Unwrap: gift wrap → seal → rumor\n        rumor, sender, err := nip17.Unwrap(wrap, a.signer)\n        if err != nil { continue }\n        \n        // Route to command processor\n        a.processIncomingDM(sender, rumor)\n    }\n}\n```\n\n### 4. DM Command Router\n\nParse incoming DMs as commands and execute:\n\n```go\nfunc (a *Agent) processIncomingDM(senderPubkey string, rumor *nostr.Event) {\n    content := strings.TrimSpace(rumor.Content)\n    \n    // Parse command: \"assign Toast gt-123\" → cmd=\"assign\", args=[\"Toast\",\"gt-123\"]\n    parts := strings.Fields(content)\n    if len(parts) == 0 { return }\n    \n    cmd := strings.ToLower(parts[0])\n    args := parts[1:]\n    \n    var response string\n    var err error\n    \n    switch cmd {\n    case \"assign\":\n        response, err = a.handleAssign(args)\n    case \"status\":\n        response, err = a.handleStatus(args)\n    case \"pause\":\n        response, err = a.handlePause(args)\n    case \"resume\":\n        response, err = a.handleResume(args)\n    case \"help\":\n        response = a.helpText()\n    default:\n        response = fmt.Sprintf(\"Unknown command: %s. Try 'help' for available commands.\", cmd)\n    }\n    \n    // Reply via NIP-17 DM\n    a.SendDM(senderPubkey, response, [][]string{\n        {\"e\", rumor.ID},  // reference original message\n    })\n}\n```\n\n#### Command Tables Per Role\n\n**Mayor**:\n| Command | Args | Action |\n|---------|------|---------|\n| `assign` | `<polecat> <issue>` | `gt sling <issue> -t <polecat>` |\n| `status` | (none) | Return summary of all rigs, agents, convoys |\n| `kill` | `<target>` | `gt kill <target>` |\n| `spawn` | `<count>` | `gt spawn <count>` |\n| `convoy` | `<convoy-id>` | Return convoy status |\n\n**Witness**:\n| Command | Args | Action |\n|---------|------|---------|\n| `status` | (none) | Return patrol/merge queue status |\n| `merge-queue` | (none) | Return merge queue details |\n| `patrol` | (none) | Trigger immediate patrol |\n| `nudge` | `<polecat>` | Nudge a polecat |\n\n**Refinery**:\n| Command | Args | Action |\n|---------|------|---------|\n| `status` | (none) | Return merge processing status |\n| `pause` | (none) | Pause merge processing |\n| `resume` | (none) | Resume merge processing |\n| `retry` | `<branch>` | Retry failed merge |\n\n**Deacon**:\n| Command | Args | Action |\n|---------|------|---------|\n| `restart` | `<role> <rig>` | Kill + respawn agent |\n| `agents` | (none) | List all agents and status |\n| `spool` | (none) | Show spool status |\n| `drain` | (none) | Force spool drain |\n\n### 5. Channel Message Handling\n\nAgents respond to channel mentions:\n\n```go\nfunc (a *Agent) processChannelMessage(event *nostr.Event) {\n    // Check if agent is mentioned\n    mentioned := false\n    for _, tag := range event.Tags {\n        if tag[0] == \"p\" && tag[1] == a.pubkey {\n            mentioned = true\n            break\n        }\n    }\n    \n    // Also check for @role text mentions\n    if !mentioned && strings.Contains(event.Content, \"@\"+a.role) {\n        mentioned = true\n    }\n    \n    if !mentioned { return }\n    \n    // Parse content as command (strip @mention prefix)\n    content := stripMention(event.Content, a.role)\n    response := a.processCommand(content)\n    \n    // Reply in channel (kind 42)\n    reply := &nostr.Event{\n        Kind:    42,\n        Content: response,\n        Tags: [][]string{\n            {\"e\", channelCreateEventID, relay, \"root\"},\n            {\"p\", event.PubKey, relay},  // mention the sender\n        },\n    }\n    a.publisher.Publish(ctx, reply)\n}\n```\n\n### 6. Protocol Event Surfacing in Channels\n\nThe Deacon posts human-readable summaries of protocol events to channels:\n\n| Protocol Event | Target Channel | Summary Format |\n|---------------|----------------|-----------------|\n| `MERGE_READY` | `#<rig>-merge` | \"🔀 Toast's branch `feature/auth` ready for merge (gt-123)\" |\n| `MERGED` | `#<rig>-merge`, `#<rig>-dev` | \"✅ `feature/auth` merged to main (abc1234)\" |\n| `MERGE_FAILED` | `#<rig>-merge`, `#alerts` | \"❌ Merge failed for `feature/auth`: test failures\" |\n| `POLECAT_DONE` | `#<rig>-dev` | \"🏁 Toast completed work on gt-123 (exit: MERGED)\" |\n| `HELP` | `#alerts` | \"⚠️ Toast needs help: stuck on test failures for gt-123\" |\n| `session_death` | `#alerts` | \"💀 Session gt-gastown-Toast died (OOM kill)\" |\n| `mass_death` | `#alerts`, `#town-ops` | \"🚨 Mass death: 5 sessions died in 60s\" |\n\n```go\nfunc (d *Deacon) surfaceProtocolEvent(event *nostr.Event) {\n    msgType := event.Tags.GetFirst([]string{\"msg_type\"}).Value()\n    summary := d.formatProtocolSummary(msgType, event)\n    channels := d.getTargetChannels(msgType)\n    \n    for _, channelID := range channels {\n        msg := &nostr.Event{\n            Kind:    42,\n            Content: summary,\n            Tags:    [][]string{{\"e\", channelID, relay, \"root\"}},\n        }\n        d.publisher.Publish(ctx, msg)\n    }\n}\n```\n\n### 7. Interrupt Delivery via DM\n\nReplace `tmux.NudgeSession` / `tmux.SendNotificationBanner` with NIP-17 DMs:\n\n```go\nfunc (a *Agent) SendInterrupt(recipientActor, message string) error {\n    pubkey, _ := a.registry.Lookup(recipientActor)\n    \n    return a.SendDM(pubkey.Pubkey, \"⚡ INTERRUPT: \"+message, [][]string{\n        {\"subject\", \"INTERRUPT: \" + message},\n        {\"priority\", \"urgent\"},\n    })\n}\n```\n\nAgent DM listener handles `priority=urgent` immediately (interrupting current work), while `priority=normal` is queued.\n\n### 8. Handoff via DM\n\nReplace protocol-event handoffs with NIP-17 DMs:\n\n```go\nfunc (a *Agent) SendHandoff(context, status, next string) error {\n    content := fmt.Sprintf(\"🤝 HANDOFF: %s\\n\\n## Context\\n%s\\n\\n## Status\\n%s\\n\\n## Next\\n%s\",\n        a.currentTopic, context, status, next)\n    \n    return a.SendDM(a.pubkey, content, [][]string{  // DM to self\n        {\"subject\", \"HANDOFF: \" + a.currentTopic},\n    })\n}\n```\n\n## Files to Modify\n\n| File | Changes |\n|------|---------|\n| `internal/session/startup.go` | Start DM listener, subscribe to channels on spawn |\n| `internal/witness/` | Add DM command router, channel message handler |\n| `internal/refinery/` | Add DM command router |\n| `internal/mayor/` | Add DM command router |\n| `internal/deacon/` | Add protocol event surfacing, DM command router |\n| `internal/polecat/` | Add channel message handler for #<rig>-dev |\n| `internal/tmux/` (nudge) | Replace NudgeSession with NIP-17 DM interrupt |\n| CLI: `gt init` | Add channel creation |\n| CLI: `gt rig add` | Add per-rig channel creation |\n\n## Files to Create\n\n| File | Purpose |\n|------|---------|\n| `internal/nostr/dm.go` | NIP-17 DM send/receive (gift wrap, seal, unwrap) |\n| `internal/nostr/channels.go` | NIP-28 channel creation, message posting |\n| `internal/nostr/commands.go` | DM command router framework |\n| `internal/nostr/interrupt.go` | Interrupt delivery via DM |\n| `internal/nostr/handoff.go` | Handoff via DM |\n| `internal/nostr/surfacing.go` | Protocol event → channel summary posting |\n\n## Security Considerations\n\n- **NIP-44 encryption**: All DMs are encrypted end-to-end (NIP-17 requirement)\n- **Gift wrapping**: Observer cannot see sender, recipient, or content of DMs\n- **Channel messages are public**: Don't put sensitive data in NIP-28 channels\n- **Interrupt priority**: `urgent` DMs bypass normal processing queue\n- **Authorization**: Verify DM sender is an authorized overseer before executing commands\n\n## Acceptance Criteria\n\n- [ ] NIP-28 channels created on `gt init` (4 town-level channels)\n- [ ] NIP-28 channels created on `gt rig add` (3 per-rig channels)\n- [ ] Channels tagged with `[\"gt\",\"1\"]` and `[\"rig\",rigName]`\n- [ ] Agent auto-subscribes to channels based on role on spawn\n- [ ] NIP-17 DM send working (kind 14 → seal → gift wrap → publish to DM relays)\n- [ ] NIP-17 DM receive working (subscribe gift wraps → unwrap → process)\n- [ ] DM command router parses and executes commands\n- [ ] Mayor, Witness, Refinery, Deacon command tables implemented\n- [ ] Channel @mention routing to correct agent\n- [ ] Agent replies in channel (kind 42)\n- [ ] Protocol events surfaced as channel messages by Deacon\n- [ ] Interrupt delivery via NIP-17 DM with priority=urgent\n- [ ] Handoff via NIP-17 DM to self/successor\n- [ ] tmux.NudgeSession replaced with DM interrupt\n- [ ] Authorization check on DM commands (reject unauthorized senders)\n- [ ] Unit tests for DM send/receive, command parsing\n- [ ] Integration test: send DM command → agent executes → DM reply"}
{"action":"create","id":"gt-nostr-ext","title":"[EXT] Build gastown-flotilla-extension Package","type":"task","priority":"high","description":"# Flotilla Extension: gastown-flotilla-extension\n\n**Parent Epic**: gt-nostr-epic\n**Depends On**: gt-nostr-p3, gt-nostr-p4, gt-nostr-p5, gt-nostr-p6, gt-nostr-p7\n**Blocks**: gt-nostr-p8\n**Estimated Effort**: Large\n\n## Objective\n\nBuild the standalone Flotilla extension package that visualizes and interacts with Gas Town via Nostr events. This is a **separate repository/package** — NO Budabit/Flotilla core files are modified.\n\n## Constraint\n\n> Gas Town integrates with Flotilla/Budabit exclusively via the `gastown-flotilla-extension` package. No Budabit core files are modified. Any core enhancements are tracked as separate upstream Flotilla PRs and are NOT prerequisites.\n\n## Package Layout\n\n```\ngastown-flotilla-extension/\n├── src/\n│   ├── index.ts                 # Extension entrypoint\n│   ├── activate.ts              # Lifecycle hooks (register routes, stores, sidebar)\n│   ├── gt/\n│   │   ├── kinds.ts             # Kind constants (30315, 30316, 30318, etc.)\n│   │   ├── filters.ts           # Shared Nostr filters (#gt=1, per-rig, etc.)\n│   │   ├── stores.ts            # Derived stores (operational + identity + work queue)\n│   │   └── types.ts             # TypeScript types for GT event content schemas\n│   ├── views/\n│   │   ├── ActivityFeed.svelte  # 30315 log stream, filter by rig/type/actor\n│   │   ├── Agents.svelte        # 30316 lifecycle + kind 0 profiles, status grid\n│   │   ├── Convoys.svelte       # 30318 convoy list with progress bars\n│   │   ├── ConvoyDetail.svelte  # 30318 + 30319 issue list, dependency graph\n│   │   ├── Issues.svelte        # 30319 issue browser, filter/sort\n│   │   ├── IssueDetail.svelte   # 30319 + 30315 related logs, blobs, deps\n│   │   └── MergeQueue.svelte    # 30325 work items, queue depth, history\n│   └── components/\n│       ├── AgentBadge.svelte          # Role badge + status from 30316\n│       ├── ProtocolEventCard.svelte   # 30320 rendered as card (MERGED, MERGE_FAILED, etc.)\n│       ├── ChannelTree.svelte         # Sidebar channel grouping by rig\n│       └── CommandAutocomplete.svelte # Agent command suggestions in DM compose\n├── extension.manifest.json      # Permissions + routes + sidebar config\n├── package.json\n├── tsconfig.json\n└── README.md\n```\n\n## Deliverables\n\n### 1. Extension Scaffold & Manifest\n- Create new repo `gastown-flotilla-extension`\n- Set up build tooling (Svelte, TypeScript, bundler)\n- Define `extension.manifest.json` with scoped permissions\n- Permissions scoped to GT kinds + `#gt=[\"1\"]` tag filter\n\n### 2. Derived Stores (`src/gt/stores.ts`)\n- `gtLogsStore` — kind 30315, last 24h, feed-visible filter\n- `gtAgentsStore` — kind 30316 grouped by actor `d` tag\n- `gtConvoysStore` — kind 30318 grouped by convoy `d` tag\n- `gtIssuesStore` — kind 30319 grouped by issue `d` tag\n- `gtWorkItemsStore` — kind 30325, grouped by queue\n- `gtAgentProfilesStore` — kind 0 with `#gt=[\"1\"]`\n- `gtActorToPubkeyMap` — derived from profiles\n- All stores use extension API (NOT direct Flotilla core imports)\n\n### 3. UI Pages (7 views)\n- **Activity Feed**: Real-time 30315 stream, color-coded event types, click→navigate\n- **Agents**: Grid/list with avatar, name, role badge, status dot (🟢🟡🟠🔴⚫), heartbeat time, current issue. Click → open DM deep-link\n- **Convoys**: List with progress bars, tracked issue counts, status badges\n- **Convoy Detail**: Issue list with statuses, worker assignments, dependency graph viz\n- **Issues**: Full browser, filter by rig/status/priority/label/assignee, sort\n- **Issue Detail**: Issue data + related logs + dependency graph + Blossom blob links\n- **Merge Queue**: Queue depth, current processing, history of merged/failed\n\n### 4. Components\n- `AgentBadge.svelte` — Role icon + status dot + display name\n- `ProtocolEventCard.svelte` — Rich card rendering for MERGED/MERGE_FAILED/HELP/etc.\n- `ChannelTree.svelte` — Discord-style sidebar tree grouped by rig\n- `CommandAutocomplete.svelte` — Command suggestions when DMing agents\n\n### 5. Sidebar & Navigation\n- Register sidebar group \"GAS TOWN\" with icon\n- Sub-groups: TOWN (town-ops, alerts, activity, announcements), per-rig channels, DMs\n- Quick links to Activity, Agents, Convoys, Issues, Merge Queue pages\n- Channel grouping from NIP-28 channels with `#gt=[\"1\"]` + `#rig` tags\n\n### 6. Chat & DM Integration (No Core Edits)\n- **DMs**: Deep-link to Flotilla's native NIP-17 DM view for agent pubkeys\n- **Channels**: Deep-link to Flotilla's native NIP-28 channel view\n- Agent discovery via kind 0 profiles with `bot: true` and `#gt=[\"1\"]`\n- Command autocomplete when DM recipient is a Gas Town agent\n\n## Files to Create\n\n| File | Purpose |\n|------|---------|\n| `gastown-flotilla-extension/package.json` | Package metadata, deps |\n| `gastown-flotilla-extension/extension.manifest.json` | Permissions, routes |\n| `gastown-flotilla-extension/src/index.ts` | Entrypoint |\n| `gastown-flotilla-extension/src/activate.ts` | Route/store/sidebar registration |\n| `gastown-flotilla-extension/src/gt/kinds.ts` | Kind constants |\n| `gastown-flotilla-extension/src/gt/filters.ts` | Nostr filter builders |\n| `gastown-flotilla-extension/src/gt/stores.ts` | Derived stores |\n| `gastown-flotilla-extension/src/gt/types.ts` | TypeScript types |\n| `gastown-flotilla-extension/src/views/*.svelte` | 7 view pages |\n| `gastown-flotilla-extension/src/components/*.svelte` | 4 components |\n| `gastown-flotilla-extension/README.md` | Setup & usage docs |\n\n## Acceptance Criteria\n\n- [ ] Extension repo created with build tooling\n- [ ] Extension manifest declares scoped permissions (GT kinds + `#gt=[\"1\"]`)\n- [ ] All derived stores subscribing to correct event kinds via extension API\n- [ ] Activity Feed page rendering real-time log stream\n- [ ] Agent dashboard showing all agents with status indicators\n- [ ] Stale agents highlighted (no heartbeat for 3× interval)\n- [ ] Convoy list with progress bars and tracked issue counts\n- [ ] Convoy detail with tracked issues and dependency graph\n- [ ] Issue browser with filter/sort by rig/status/priority/label\n- [ ] Issue detail with blobs, dependencies, related logs\n- [ ] Merge queue with queue depth and processing status\n- [ ] Sidebar group \"GAS TOWN\" with rig-grouped channels\n- [ ] DM deep-links to agent pubkeys working via native Flotilla DM view\n- [ ] Channel deep-links working via native Flotilla channel view\n- [ ] Command autocomplete in DM compose for agent commands\n- [ ] Protocol event cards rendered in channel views\n- [ ] **No Budabit/Flotilla core files modified**\n- [ ] Extension installable in Flotilla\n- [ ] Responsive layout on desktop and tablet\n- [ ] Loading states for all data-dependent views\n\n## Reference\n\n- See `docs/design/nostr-protocol.md` → Flotilla Extension Integration section\n- Store API names are illustrative; use actual Flotilla extension SDK"}
{"action":"create","id":"gt-nostr-p8","title":"[P8] Flotilla Extension Shipping & Verification","type":"task","priority":"medium","description":"# Phase 8: Flotilla Extension Shipping & Verification\n\n**Parent Epic**: gt-nostr-epic\n**Depends On**: gt-nostr-ext, gt-nostr-p3, gt-nostr-p4, gt-nostr-p5, gt-nostr-p6, gt-nostr-p7\n**Blocks**: gt-nostr-p9\n**Estimated Effort**: Medium\n\n## Objective\n\nPackage, ship, and verify the `gastown-flotilla-extension` against live relays. Confirm that the extension integrates correctly with Flotilla without any Budabit core modifications. Write operator documentation for setup, configuration, and daily use.\n\n## Constraint\n\n> This phase does NOT build the extension — that work is tracked in `gt-nostr-ext`. This phase takes the completed extension and makes it production-ready: packaging, integration testing, documentation, and release.\n\n## Deliverables\n\n### 1. Integration Test Suite\n\n- End-to-end tests: install extension into a fresh Flotilla instance\n- Verify all 7 views render with mock event data (30315–30325)\n- Verify sidebar group registration (GAS TOWN section appears)\n- Verify DM deep-links open native Flotilla NIP-17 DM view\n- Verify channel deep-links open native Flotilla NIP-28 channel view\n- Verify command autocomplete triggers in DM compose to agent pubkeys\n- Verify protocol event cards render in channel message streams\n- Verify extension manifest permissions are scoped (GT kinds + `#gt=[\"1\"]` only)\n- **Zero Budabit core file modifications** — `git diff` on Flotilla repo must be clean after extension install\n\n### 2. Live Relay Smoke Tests\n\n- Connect extension to a test relay (e.g., local `nostr-relay` or `strfry`)\n- Publish GT events from a running Gas Town instance\n- Confirm Activity Feed updates in real time\n- Confirm Agent dashboard reflects lifecycle state transitions\n- Confirm Convoy/Issue views reflect replaceable event updates\n- Confirm Merge Queue reflects work item claims and completions\n- Test offline resilience: disconnect relay, reconnect, verify catch-up\n\n### 3. Packaging & Distribution\n\n- `npm pack` or equivalent produces installable artifact\n- Version pinned to match Gas Town Nostr protocol version (v0.3.x)\n- Peer dependency on Flotilla SDK version documented\n- README with install command, configuration, and screenshots\n- CHANGELOG with initial release notes\n\n### 4. Operator Documentation\n\nWrite `gastown-flotilla-extension/docs/operator-guide.md`:\n\n- **Installation**: How to install the extension in a Flotilla instance\n- **Configuration**: Relay URLs, Deacon pubkey, rig filter settings\n- **Channels**: How Gas Town channels appear, rig grouping, town-level vs rig-level\n- **DMs with Agents**: How to find agents, start DM, use command autocomplete\n- **Activity Feed**: Reading the log stream, filtering, what events mean\n- **Convoy Dashboard**: Understanding progress bars, issue tracking, dependency graphs\n- **Issue Browser**: Filtering/sorting, viewing issue details, Blossom blob links\n- **Agent Status**: Reading status indicators (🟢🟡🟠🔴⚫), heartbeat staleness\n- **Merge Queue**: Understanding queue depth, claimed items, completion flow\n- **Troubleshooting**: Common issues (relay connectivity, missing events, stale data)\n\n### 5. Security Review\n\n- Verify extension only accesses GT-scoped event kinds\n- Verify no private key material leaks through extension stores\n- Verify NIP-17 DM encryption handled by Flotilla core (extension never sees plaintext of non-GT DMs)\n- Verify extension manifest does NOT request broader permissions than needed\n\n## Files to Create\n\n| File | Purpose |\n|------|---------|\n| `gastown-flotilla-extension/tests/integration/install.test.ts` | Extension install test |\n| `gastown-flotilla-extension/tests/integration/views.test.ts` | View rendering tests |\n| `gastown-flotilla-extension/tests/integration/navigation.test.ts` | Deep-link and sidebar tests |\n| `gastown-flotilla-extension/tests/smoke/relay.test.ts` | Live relay smoke tests |\n| `gastown-flotilla-extension/tests/smoke/offline.test.ts` | Offline resilience tests |\n| `gastown-flotilla-extension/docs/operator-guide.md` | Operator documentation |\n| `gastown-flotilla-extension/CHANGELOG.md` | Release notes |\n\n## Acceptance Criteria\n\n- [ ] Extension installs into Flotilla with zero core file modifications\n- [ ] `git diff` on Flotilla repo is clean after extension install + activation\n- [ ] All 7 views render correctly with mock GT events\n- [ ] Sidebar group \"GAS TOWN\" appears with correct channel tree\n- [ ] DM and channel deep-links work via native Flotilla views\n- [ ] Command autocomplete works in DM compose to agent pubkeys\n- [ ] Protocol event cards render in channel views\n- [ ] Live relay smoke tests pass (real GT events from running instance)\n- [ ] Offline disconnect/reconnect catch-up works\n- [ ] Extension manifest permissions are minimally scoped\n- [ ] Operator guide covers all UI sections with examples\n- [ ] Security review checklist complete — no permission overreach\n- [ ] Packaged artifact installable via npm/package manager\n- [ ] Version matches GT Nostr protocol version"}
{"action":"create","id":"gt-nostr-p2.5","title":"[P2.5] LLM Client Abstraction & Network Agent Loop","type":"task","priority":"high","description":"# Phase 2.5: LLM Client Abstraction & Network Agent Loop\n\n**Parent Epic**: gt-nostr-epic\n**Depends On**: gt-nostr-p2\n**Blocks**: gt-nostr-p7, gt-nostr-p8\n**Estimated Effort**: X-Large\n\n## Objective\n\nDecouple Gastown's agent execution from the tmux/CLI model by introducing:\n1. An **LLM Client interface** for calling remote/local models via OpenAI-compatible APIs\n2. A **Go-native Agent Loop** that replaces tmux sessions for API-mode agents\n3. An **MCP Server** that exposes GT/BD tools over the network for remote agent processes\n4. A **ProviderType** extension to `AgentPresetInfo` that distinguishes CLI vs API vs MCP agents\n\nThis enables running polecat workers, witness, refinery, etc. against LLMs hosted on other machines on the local network (e.g., Ollama on a GPU server at `192.168.1.50:11434`), cloud APIs (OpenAI, Anthropic HTTP), or local models — all without requiring tmux sessions.\n\n## Background\n\n### Current Architecture (tmux-bound)\n\nEvery agent in Gastown currently runs as a **CLI process inside a tmux session**:\n\n```\nSessionManager.Start()\n  → ResolveRoleAgentConfig() → RuntimeConfig\n  → tmux.NewSessionWithCommand(sessionID, workDir, command)\n  → tmux.SetEnvironment() for GT_* vars\n  → tmux.WaitForCommand() for agent ready\n  → tmux.NudgeSession() for work instructions\n```\n\nKey files:\n- `internal/polecat/session_manager.go` — `Start()` creates tmux sessions, `Inject()` sends text, `Stop()` kills sessions\n- `internal/config/agents.go` — `AgentPresetInfo` defines CLI command/args/env, `RuntimeConfig` builds shell commands\n- `internal/config/loader.go` — `ResolveRoleAgentConfig()` resolves role→agent→config chain\n- `internal/tmux/` — All process interaction goes through tmux SendKeys/NudgeSession\n- `internal/runtime/` — Hook installation, startup fallback, ready detection\n\nThis works well for CLI agents (Claude, Gemini, Codex) but **cannot** handle:\n- HTTP API endpoints (Ollama, vLLM, OpenAI API, Anthropic API)\n- LLMs on remote machines (no tmux session possible)\n- MCP server-based agents\n- Custom agent loops with tool-use\n\n### Target Architecture (provider-agnostic)\n\n```\nResolveRoleAgentConfig() → RuntimeConfig with ProviderType\n  ├── ProviderType=cli   → existing tmux flow (unchanged)\n  ├── ProviderType=api   → Go-native AgentLoop + LLMClient\n  └── ProviderType=mcp   → MCP client connecting to remote agent\n```\n\n## Deliverables\n\n### 1. ProviderType Extension (`internal/config/agents.go`)\n\nExtend `AgentPresetInfo` with a provider type discriminator:\n\n```go\n// ProviderType determines how the agent process is managed.\ntype ProviderType string\n\nconst (\n    // ProviderCLI is the default — agent runs as a CLI process in a tmux session.\n    ProviderCLI ProviderType = \"cli\"\n    // ProviderAPI means Gastown runs an agent loop in Go, calling a remote LLM API.\n    ProviderAPI ProviderType = \"api\"\n    // ProviderMCP means the agent runs externally and connects back via MCP for tools.\n    ProviderMCP ProviderType = \"mcp\"\n)\n\n// APIConfig holds configuration for ProviderAPI agents.\ntype APIConfig struct {\n    // BaseURL is the OpenAI-compatible API endpoint.\n    // Examples: \"http://192.168.1.50:11434/v1\" (Ollama),\n    //          \"https://api.openai.com/v1\" (OpenAI),\n    //          \"https://api.anthropic.com\" (Anthropic)\n    BaseURL string `json:\"base_url\"`\n\n    // Model is the model identifier.\n    // Examples: \"llama3.1:70b\" (Ollama), \"gpt-4\" (OpenAI), \"claude-sonnet-4-20250514\" (Anthropic)\n    Model string `json:\"model\"`\n\n    // APIKey is the API key (empty for local endpoints like Ollama).\n    // Can reference env var: \"$OLLAMA_API_KEY\" or \"$OPENAI_API_KEY\"\n    APIKey string `json:\"api_key,omitempty\"`\n\n    // APIType selects the wire protocol.\n    // \"openai\" (default, works with Ollama/vLLM/OpenAI/most providers)\n    // \"anthropic\" (for Anthropic's native API format)\n    APIType string `json:\"api_type,omitempty\"`\n\n    // MaxTokens is the maximum tokens per response. Default: 4096.\n    MaxTokens int `json:\"max_tokens,omitempty\"`\n\n    // Temperature controls randomness. Default: 0.0 (deterministic for code tasks).\n    Temperature *float64 `json:\"temperature,omitempty\"`\n\n    // SupportsTools indicates if the model supports tool-use/function-calling.\n    // If false, the agent loop falls back to text-based tool invocation (prompt-based).\n    SupportsTools bool `json:\"supports_tools\"`\n\n    // SupportsVision indicates if the model can process images.\n    SupportsVision bool `json:\"supports_vision,omitempty\"`\n\n    // ContextWindow is the model's context window size in tokens.\n    // Used by the agent loop to manage context truncation.\n    ContextWindow int `json:\"context_window,omitempty\"`\n\n    // SystemPrompt is prepended to every conversation.\n    // If empty, the agent loop uses role-specific defaults from CLAUDE.md/AGENTS.md.\n    SystemPrompt string `json:\"system_prompt,omitempty\"`\n\n    // Headers are additional HTTP headers for the API request.\n    // Useful for auth proxies, custom routing, etc.\n    Headers map[string]string `json:\"headers,omitempty\"`\n\n    // Timeout is the HTTP request timeout. Default: 300s.\n    TimeoutSeconds int `json:\"timeout_seconds,omitempty\"`\n\n    // RetryConfig controls retry behavior on transient failures.\n    Retry *RetryConfig `json:\"retry,omitempty\"`\n}\n\n// RetryConfig controls retry behavior for API calls.\ntype RetryConfig struct {\n    MaxRetries     int `json:\"max_retries\"`      // Default: 3\n    InitialBackoff int `json:\"initial_backoff_ms\"` // Default: 1000\n    MaxBackoff     int `json:\"max_backoff_ms\"`     // Default: 30000\n}\n\n// MCPConfig holds configuration for ProviderMCP agents.\ntype MCPConfig struct {\n    // ServerURL is the MCP server endpoint the remote agent connects TO.\n    // This is the GT tool server that Gastown runs.\n    // Example: \"http://192.168.1.10:9500/mcp\" (your machine)\n    ServerURL string `json:\"server_url\"`\n\n    // TransportType is the MCP transport protocol.\n    // \"sse\" (Server-Sent Events, default), \"stdio\" (for local processes), \"ws\" (WebSocket)\n    TransportType string `json:\"transport_type,omitempty\"`\n\n    // AuthToken is a bearer token for MCP server authentication.\n    // Can reference env var: \"$GT_MCP_TOKEN\"\n    AuthToken string `json:\"auth_token,omitempty\"`\n\n    // ExposedTools controls which GT tools are exposed to the remote agent.\n    // Default: all tools. Can be restricted per role for security.\n    ExposedTools []string `json:\"exposed_tools,omitempty\"`\n\n    // RemoteAgentURL is optional — if set, Gastown also acts as MCP client\n    // connecting to the remote agent's MCP server for bidirectional communication.\n    RemoteAgentURL string `json:\"remote_agent_url,omitempty\"`\n}\n```\n\nExtend `AgentPresetInfo`:\n\n```go\ntype AgentPresetInfo struct {\n    // ... existing fields ...\n\n    // ProviderType determines the execution model.\n    // \"cli\" (default) = tmux session, \"api\" = Go agent loop, \"mcp\" = external MCP agent.\n    ProviderType ProviderType `json:\"provider_type,omitempty\"`\n\n    // API holds configuration for provider_type=\"api\" agents.\n    API *APIConfig `json:\"api,omitempty\"`\n\n    // MCP holds configuration for provider_type=\"mcp\" agents.\n    MCP *MCPConfig `json:\"mcp,omitempty\"`\n}\n```\n\nBackward compatibility: `ProviderType` defaults to `\"cli\"` when empty, preserving all existing behavior.\n\n### 2. LLM Client Interface (`internal/llm/client.go`)\n\nNew package `internal/llm/` providing a unified interface for calling language models:\n\n```go\npackage llm\n\n// Client is the interface for calling language models.\n// Implementations handle wire protocol differences (OpenAI, Anthropic, etc.)\ntype Client interface {\n    // Chat sends a conversation and returns the model's response.\n    // tools defines available function-calling tools.\n    Chat(ctx context.Context, req *ChatRequest) (*ChatResponse, error)\n\n    // Stream sends a conversation and returns a streaming response channel.\n    // Each chunk contains either text content or a tool call.\n    Stream(ctx context.Context, req *ChatRequest) (<-chan StreamChunk, error)\n\n    // ModelInfo returns information about the connected model.\n    ModelInfo() *ModelInfo\n\n    // Ping checks if the API endpoint is reachable.\n    Ping(ctx context.Context) error\n\n    // Close releases any resources (HTTP connections, etc.)\n    Close() error\n}\n\n// ChatRequest is the input to a Chat/Stream call.\ntype ChatRequest struct {\n    Messages    []Message     `json:\"messages\"`\n    Tools       []ToolDef     `json:\"tools,omitempty\"`\n    MaxTokens   int           `json:\"max_tokens,omitempty\"`\n    Temperature *float64      `json:\"temperature,omitempty\"`\n    StopSeqs    []string      `json:\"stop,omitempty\"`\n}\n\n// Message represents a conversation message.\ntype Message struct {\n    Role       string         `json:\"role\"`    // \"system\", \"user\", \"assistant\", \"tool\"\n    Content    string         `json:\"content\"`\n    ToolCalls  []ToolCall     `json:\"tool_calls,omitempty\"`\n    ToolCallID string         `json:\"tool_call_id,omitempty\"` // for role=\"tool\" responses\n    Name       string         `json:\"name,omitempty\"`\n}\n\n// ToolDef defines a tool the model can call.\ntype ToolDef struct {\n    Name        string          `json:\"name\"`\n    Description string          `json:\"description\"`\n    Parameters  json.RawMessage `json:\"parameters\"` // JSON Schema\n}\n\n// ToolCall represents the model requesting a tool invocation.\ntype ToolCall struct {\n    ID       string          `json:\"id\"`\n    Name     string          `json:\"name\"`\n    Args     json.RawMessage `json:\"arguments\"`\n}\n\n// ChatResponse is the model's complete response.\ntype ChatResponse struct {\n    Content    string     `json:\"content\"`\n    ToolCalls  []ToolCall `json:\"tool_calls,omitempty\"`\n    Usage      *Usage     `json:\"usage,omitempty\"`\n    FinishReason string   `json:\"finish_reason\"`\n}\n\n// StreamChunk is a single piece of a streaming response.\ntype StreamChunk struct {\n    Type       ChunkType  // TextChunk or ToolCallChunk\n    Text       string     // for TextChunk\n    ToolCall   *ToolCall  // for ToolCallChunk (may be partial)\n    Done       bool       // true on final chunk\n    Err        error      // non-nil on stream error\n}\n\ntype ChunkType int\nconst (\n    TextChunk ChunkType = iota\n    ToolCallChunk\n)\n\n// Usage tracks token consumption.\ntype Usage struct {\n    PromptTokens     int `json:\"prompt_tokens\"`\n    CompletionTokens int `json:\"completion_tokens\"`\n    TotalTokens      int `json:\"total_tokens\"`\n}\n\n// ModelInfo describes the connected model.\ntype ModelInfo struct {\n    ID            string `json:\"id\"`\n    Provider      string `json:\"provider\"` // \"ollama\", \"openai\", \"anthropic\", \"vllm\"\n    ContextWindow int    `json:\"context_window\"`\n    SupportsTools bool   `json:\"supports_tools\"`\n    SupportsVision bool  `json:\"supports_vision\"`\n}\n```\n\n### 3. OpenAI-Compatible Client (`internal/llm/openai.go`)\n\nImplementation that works with Ollama, vLLM, OpenAI, and any OpenAI-compatible endpoint:\n\n```go\n// OpenAIClient implements Client for OpenAI-compatible APIs.\n// This works with:\n// - Ollama (http://hostname:11434/v1)\n// - vLLM (http://hostname:8000/v1)\n// - OpenAI (https://api.openai.com/v1)\n// - Azure OpenAI\n// - LiteLLM proxy\n// - Any OpenAI-compatible endpoint\ntype OpenAIClient struct {\n    baseURL    string\n    apiKey     string\n    model      string\n    httpClient *http.Client\n    headers    map[string]string\n}\n\nfunc NewOpenAIClient(cfg *config.APIConfig) (*OpenAIClient, error)\n```\n\nEndpoints called:\n- `POST /chat/completions` (main inference)\n- `GET /models` (model info / ping)\n- Handles SSE streaming (`stream: true`)\n\n### 4. Anthropic Client (`internal/llm/anthropic.go`)\n\nFor direct Anthropic API calls (different wire format than OpenAI):\n\n```go\n// AnthropicClient implements Client for Anthropic's Messages API.\ntype AnthropicClient struct {\n    baseURL    string\n    apiKey     string\n    model      string\n    httpClient *http.Client\n}\n\nfunc NewAnthropicClient(cfg *config.APIConfig) (*AnthropicClient, error)\n```\n\nEndpoints:\n- `POST /v1/messages` (inference)\n- Handles SSE streaming\n- Maps Anthropic's tool_use blocks to the unified ToolCall type\n\n### 5. Client Factory (`internal/llm/factory.go`)\n\n```go\n// NewClient creates an LLM client from config.\nfunc NewClient(cfg *config.APIConfig) (Client, error) {\n    apiType := cfg.APIType\n    if apiType == \"\" {\n        apiType = \"openai\" // default\n    }\n    switch apiType {\n    case \"openai\":\n        return NewOpenAIClient(cfg)\n    case \"anthropic\":\n        return NewAnthropicClient(cfg)\n    default:\n        return nil, fmt.Errorf(\"unsupported api_type: %s\", apiType)\n    }\n}\n```\n\n### 6. GT Tool Definitions (`internal/agentloop/tools.go`)\n\nDefine all Gastown operations as tool-call-compatible tool definitions:\n\n```go\n// GTTools returns the tool definitions for Gastown operations.\n// These are exposed to API-mode agents as function-calling tools\n// and to MCP-mode agents as MCP tools.\nfunc GTTools() []llm.ToolDef {\n    return []llm.ToolDef{\n        {\n            Name: \"gt_prime\",\n            Description: \"Read current work assignment and context. Call this first when starting work.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{},\"required\":[]}`)},\n        },\n        {\n            Name: \"gt_done\",\n            Description: \"Mark current task as complete. Commits work and signals the witness.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{\"message\":{\"type\":\"string\",\"description\":\"Completion summary\"}},\"required\":[\"message\"]}`)},\n        },\n        {\n            Name: \"bd_show\",\n            Description: \"Show details of a beads issue.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{\"issue_id\":{\"type\":\"string\"}},\"required\":[\"issue_id\"]}`)},\n        },\n        {\n            Name: \"bd_list\",\n            Description: \"List beads issues with optional filters.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{\"status\":{\"type\":\"string\"},\"label\":{\"type\":\"string\"}},\"required\":[]}`)},\n        },\n        {\n            Name: \"git_diff\",\n            Description: \"Show git diff of current changes.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{\"staged\":{\"type\":\"boolean\"}},\"required\":[]}`)},\n        },\n        {\n            Name: \"git_status\",\n            Description: \"Show git status of the working directory.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{},\"required\":[]}`)},\n        },\n        {\n            Name: \"file_read\",\n            Description: \"Read file contents.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{\"path\":{\"type\":\"string\"},\"start_line\":{\"type\":\"integer\"},\"end_line\":{\"type\":\"integer\"}},\"required\":[\"path\"]}`)},\n        },\n        {\n            Name: \"file_write\",\n            Description: \"Write content to a file. Creates parent directories if needed.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{\"path\":{\"type\":\"string\"},\"content\":{\"type\":\"string\"}},\"required\":[\"path\",\"content\"]}`)},\n        },\n        {\n            Name: \"file_edit\",\n            Description: \"Apply a search-and-replace edit to a file.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{\"path\":{\"type\":\"string\"},\"search\":{\"type\":\"string\"},\"replace\":{\"type\":\"string\"}},\"required\":[\"path\",\"search\",\"replace\"]}`)},\n        },\n        {\n            Name: \"shell_exec\",\n            Description: \"Execute a shell command in the working directory. Use sparingly.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{\"command\":{\"type\":\"string\"},\"timeout_seconds\":{\"type\":\"integer\"}},\"required\":[\"command\"]}`)},\n        },\n        {\n            Name: \"gt_mail_send\",\n            Description: \"Send a message to another agent or channel.\",\n            Parameters: json.RawMessage(`{\"type\":\"object\",\"properties\":{\"to\":{\"type\":\"string\"},\"subject\":{\"type\":\"string\"},\"body\":{\"type\":\"string\"}},\"required\":[\"to\",\"subject\"]}`)},\n        },\n    }\n}\n```\n\n### 7. Tool Executor (`internal/agentloop/executor.go`)\n\nExecutes tool calls locally (in the git worktree context):\n\n```go\n// Executor handles tool call execution in a specific working directory.\ntype Executor struct {\n    workDir   string          // git worktree path\n    rigName   string\n    rigPath   string\n    townRoot  string\n    actor     string          // e.g., \"gastown/polecats/Toast\"\n    beadsDir  string          // beads repo path\n}\n\nfunc NewExecutor(workDir, rigName, rigPath, townRoot, actor string) *Executor\n\n// Execute runs a tool call and returns the result as a string.\nfunc (e *Executor) Execute(ctx context.Context, call llm.ToolCall) (string, error) {\n    switch call.Name {\n    case \"gt_prime\":\n        return e.execGTPrime(ctx)\n    case \"gt_done\":\n        return e.execGTDone(ctx, call.Args)\n    case \"bd_show\":\n        return e.execBDShow(ctx, call.Args)\n    case \"file_read\":\n        return e.execFileRead(ctx, call.Args)\n    case \"file_write\":\n        return e.execFileWrite(ctx, call.Args)\n    case \"file_edit\":\n        return e.execFileEdit(ctx, call.Args)\n    case \"shell_exec\":\n        return e.execShell(ctx, call.Args)\n    // ... etc\n    default:\n        return \"\", fmt.Errorf(\"unknown tool: %s\", call.Name)\n    }\n}\n```\n\nCritical: Tool execution happens on the **local machine** (where the git repo lives), regardless of where the LLM runs. This is the key insight — the LLM thinks remotely, tools execute locally.\n\n### 8. Agent Loop (`internal/agentloop/loop.go`)\n\nThe Go-native agent loop that replaces tmux sessions for API-mode agents:\n\n```go\n// AgentLoop orchestrates the think→act→observe cycle for API-mode agents.\n// It replaces the tmux session + CLI agent pattern with a Go-native loop\n// that calls a remote LLM API and executes tools locally.\ntype AgentLoop struct {\n    client     llm.Client       // Remote LLM\n    executor   *Executor        // Local tool execution\n    publisher  *nostr.Publisher // Nostr event publishing (Phase 2)\n    identity   *nostr.Identity  // Agent's Nostr identity (Phase 2)\n    tools      []llm.ToolDef    // Available tools\n    messages   []llm.Message    // Conversation history\n    config     *AgentLoopConfig\n    cancelFunc context.CancelFunc\n    done       chan struct{}\n}\n\n// AgentLoopConfig controls loop behavior.\ntype AgentLoopConfig struct {\n    // SystemPrompt is the system message prepended to every conversation.\n    // Loaded from CLAUDE.md/AGENTS.md or from APIConfig.SystemPrompt.\n    SystemPrompt string\n\n    // MaxIterations limits the think→act→observe cycles per task.\n    // Prevents infinite loops. Default: 50.\n    MaxIterations int\n\n    // MaxTokensPerTask limits total token usage per task.\n    // Prevents runaway costs. Default: 200000.\n    MaxTokensPerTask int\n\n    // IdleTimeout is how long to wait for work before the loop sleeps.\n    // Default: 5 minutes.\n    IdleTimeout time.Duration\n\n    // ToolTimeout is the maximum time for a single tool execution.\n    // Default: 120 seconds.\n    ToolTimeout time.Duration\n\n    // Role is the agent's role (polecat, witness, refinery, etc.)\n    Role string\n\n    // RigName is the rig this agent is working on.\n    RigName string\n}\n\n// NewAgentLoop creates an agent loop for an API-mode agent.\nfunc NewAgentLoop(client llm.Client, executor *Executor, cfg *AgentLoopConfig) *AgentLoop\n\n// Start begins the agent loop. It:\n// 1. Calls gt_prime to get work assignment\n// 2. Enters the think→act→observe cycle\n// 3. Calls gt_done when complete\n// 4. Returns to idle (waiting for next assignment via Nostr DM or direct call)\nfunc (l *AgentLoop) Start(ctx context.Context) error\n\n// AssignWork sends a new task to the running agent loop.\n// Equivalent to tmux NudgeSession but without tmux.\nfunc (l *AgentLoop) AssignWork(task string) error\n\n// Stop gracefully stops the agent loop.\nfunc (l *AgentLoop) Stop() error\n\n// Status returns the current loop state.\nfunc (l *AgentLoop) Status() *LoopStatus\n```\n\nThe core loop:\n\n```go\nfunc (l *AgentLoop) runTask(ctx context.Context, task string) error {\n    // 1. Add task to conversation\n    l.messages = append(l.messages, llm.Message{\n        Role: \"user\", Content: task,\n    })\n\n    for i := 0; i < l.config.MaxIterations; i++ {\n        // 2. Think: call LLM\n        resp, err := l.client.Chat(ctx, &llm.ChatRequest{\n            Messages: l.messages,\n            Tools:    l.tools,\n        })\n        if err != nil {\n            return fmt.Errorf(\"LLM call failed: %w\", err)\n        }\n\n        // 3. Add assistant response to history\n        l.messages = append(l.messages, llm.Message{\n            Role: \"assistant\", Content: resp.Content, ToolCalls: resp.ToolCalls,\n        })\n\n        // 4. If no tool calls, task is complete\n        if len(resp.ToolCalls) == 0 {\n            return nil // done\n        }\n\n        // 5. Act: execute each tool call\n        for _, tc := range resp.ToolCalls {\n            result, err := l.executor.Execute(ctx, tc)\n            if err != nil {\n                result = fmt.Sprintf(\"Error: %v\", err)\n            }\n\n            // 6. Observe: add tool result to conversation\n            l.messages = append(l.messages, llm.Message{\n                Role: \"tool\", Content: result, ToolCallID: tc.ID,\n            })\n        }\n\n        // 7. Publish heartbeat (Nostr lifecycle event)\n        l.publishHeartbeat()\n    }\n\n    return fmt.Errorf(\"max iterations (%d) reached\", l.config.MaxIterations)\n}\n```\n\n### 9. Session Manager Extension (`internal/polecat/session_manager.go`)\n\nExtend `SessionManager.Start()` to handle API-mode agents:\n\n```go\nfunc (m *SessionManager) Start(polecat string, opts SessionStartOptions) error {\n    // ... existing polecat validation ...\n\n    // Resolve runtime config\n    townRoot := filepath.Dir(m.rig.Path)\n    runtimeConfig := config.ResolveRoleAgentConfig(\"polecat\", townRoot, m.rig.Path)\n\n    // Branch on provider type\n    switch runtimeConfig.ProviderType {\n    case config.ProviderAPI:\n        return m.startAPIAgent(polecat, opts, runtimeConfig)\n    case config.ProviderMCP:\n        return m.startMCPAgent(polecat, opts, runtimeConfig)\n    default: // config.ProviderCLI or empty\n        return m.startCLIAgent(polecat, opts, runtimeConfig)  // existing tmux flow\n    }\n}\n\nfunc (m *SessionManager) startAPIAgent(polecat string, opts SessionStartOptions, rc *config.RuntimeConfig) error {\n    // 1. Create worktree (same as CLI)\n    workDir := opts.WorkDir\n    if workDir == \"\" {\n        workDir = m.clonePath(polecat)\n    }\n\n    // 2. Create LLM client\n    client, err := llm.NewClient(rc.API)\n    if err != nil {\n        return fmt.Errorf(\"creating LLM client: %w\", err)\n    }\n\n    // 3. Ping to verify connectivity\n    if err := client.Ping(context.Background()); err != nil {\n        return fmt.Errorf(\"LLM endpoint unreachable at %s: %w\", rc.API.BaseURL, err)\n    }\n\n    // 4. Create tool executor (local)\n    executor := agentloop.NewExecutor(workDir, m.rig.Name, m.rig.Path, townRoot, actor)\n\n    // 5. Load system prompt (from CLAUDE.md/AGENTS.md or config)\n    systemPrompt := loadSystemPrompt(rc, workDir)\n\n    // 6. Create and start agent loop\n    loop := agentloop.NewAgentLoop(client, executor, &agentloop.AgentLoopConfig{\n        SystemPrompt: systemPrompt,\n        Role:         \"polecat\",\n        RigName:      m.rig.Name,\n    })\n\n    // 7. Store loop reference (replaces tmux session tracking)\n    m.apiLoops[polecat] = loop\n\n    // 8. Start loop in background\n    go loop.Start(context.Background())\n\n    return nil\n}\n```\n\n### 10. MCP Tool Server (`internal/mcp/server.go`)\n\nFor ProviderMCP agents — exposes GT tools as an MCP server that remote agents connect to:\n\n```go\npackage mcp\n\n// Server exposes Gastown tools via MCP protocol.\n// Remote agents (on GPU servers, etc.) connect to this server\n// to access git repos, beads, and GT commands on the local machine.\ntype Server struct {\n    addr        string\n    tools       map[string]ToolHandler\n    authToken   string\n    executor    *agentloop.Executor\n}\n\n// ToolHandler is a function that handles an MCP tool call.\ntype ToolHandler func(ctx context.Context, args json.RawMessage) (string, error)\n\nfunc NewServer(addr string, executor *agentloop.Executor, authToken string) *Server\n\n// RegisterTool adds a tool to the MCP server.\nfunc (s *Server) RegisterTool(name, description string, schema json.RawMessage, handler ToolHandler)\n\n// RegisterGTTools registers all standard GT tools.\nfunc (s *Server) RegisterGTTools()\n\n// Start begins listening for MCP connections.\n// Supports SSE transport (HTTP) for network access.\nfunc (s *Server) Start(ctx context.Context) error\n\n// Stop gracefully shuts down the server.\nfunc (s *Server) Stop() error\n```\n\nThe MCP server:\n- Listens on a configurable port (default: 9500)\n- Authenticates via bearer token (from `MCPConfig.AuthToken`)\n- Exposes the same tools as the agent loop (gt_prime, gt_done, file_read, etc.)\n- Runs on the machine with the git repo\n- Remote agents connect via SSE transport\n\n### 11. Network Discovery (`internal/mcp/discovery.go`)\n\nFor LAN setups — helps agents find each other:\n\n```go\n// Discovery handles mDNS/DNS-SD for GT MCP servers on the LAN.\ntype Discovery struct {\n    serviceName string // \"_gastown._tcp\"\n}\n\nfunc NewDiscovery() *Discovery\n\n// Advertise publishes this MCP server on the local network.\nfunc (d *Discovery) Advertise(port int, metadata map[string]string) error\n\n// Discover finds GT MCP servers on the local network.\nfunc (d *Discovery) Discover(timeout time.Duration) ([]ServiceInfo, error)\n\ntype ServiceInfo struct {\n    Host     string            `json:\"host\"`\n    Port     int               `json:\"port\"`\n    Metadata map[string]string `json:\"metadata\"` // rig, role, etc.\n}\n```\n\n### 12. Example Configurations\n\n**Ollama on GPU server (LAN):**\n```json\n{\n  \"version\": 1,\n  \"agents\": {\n    \"lan-llama\": {\n      \"name\": \"lan-llama\",\n      \"provider_type\": \"api\",\n      \"api\": {\n        \"base_url\": \"http://192.168.1.50:11434/v1\",\n        \"model\": \"llama3.1:70b\",\n        \"api_type\": \"openai\",\n        \"supports_tools\": true,\n        \"context_window\": 131072,\n        \"max_tokens\": 4096,\n        \"timeout_seconds\": 600,\n        \"retry\": {\n          \"max_retries\": 3,\n          \"initial_backoff_ms\": 2000,\n          \"max_backoff_ms\": 30000\n        }\n      }\n    },\n    \"lan-qwen\": {\n      \"name\": \"lan-qwen\",\n      \"provider_type\": \"api\",\n      \"api\": {\n        \"base_url\": \"http://192.168.1.50:11434/v1\",\n        \"model\": \"qwen2.5-coder:32b\",\n        \"api_type\": \"openai\",\n        \"supports_tools\": true,\n        \"context_window\": 32768\n      }\n    }\n  }\n}\n```\n\n**vLLM on dedicated server:**\n```json\n{\n  \"agents\": {\n    \"vllm-deepseek\": {\n      \"name\": \"vllm-deepseek\",\n      \"provider_type\": \"api\",\n      \"api\": {\n        \"base_url\": \"http://gpu-server.local:8000/v1\",\n        \"model\": \"deepseek-coder-v2-instruct\",\n        \"api_type\": \"openai\",\n        \"supports_tools\": true,\n        \"context_window\": 65536\n      }\n    }\n  }\n}\n```\n\n**Cloud API (OpenAI):**\n```json\n{\n  \"agents\": {\n    \"gpt4-api\": {\n      \"name\": \"gpt4-api\",\n      \"provider_type\": \"api\",\n      \"api\": {\n        \"base_url\": \"https://api.openai.com/v1\",\n        \"model\": \"gpt-4o\",\n        \"api_key\": \"$OPENAI_API_KEY\",\n        \"api_type\": \"openai\",\n        \"supports_tools\": true,\n        \"context_window\": 128000\n      }\n    }\n  }\n}\n```\n\n**Role assignment with mixed providers:**\n```json\n{\n  \"type\": \"town-settings\",\n  \"version\": 1,\n  \"default_agent\": \"claude\",\n  \"role_agents\": {\n    \"mayor\": \"claude\",\n    \"deacon\": \"claude\",\n    \"witness\": \"lan-qwen\",\n    \"polecat\": \"lan-llama\",\n    \"refinery\": \"lan-llama\",\n    \"crew\": \"claude\"\n  }\n}\n```\n\n## Package Structure\n\n```\ninternal/\n├── llm/                    # NEW — LLM client abstraction\n│   ├── client.go           # Client interface, types\n│   ├── openai.go           # OpenAI-compatible implementation\n│   ├── anthropic.go        # Anthropic API implementation\n│   ├── factory.go          # NewClient() factory\n│   └── client_test.go      # Tests\n├── agentloop/              # NEW — Go-native agent loop\n│   ├── loop.go             # AgentLoop orchestrator\n│   ├── tools.go            # GT tool definitions\n│   ├── executor.go         # Local tool execution\n│   ├── context.go          # Context window management\n│   └── loop_test.go        # Tests\n├── mcp/                    # NEW — MCP server for remote agents\n│   ├── server.go           # MCP tool server\n│   ├── transport.go        # SSE/stdio/WS transport\n│   ├── discovery.go        # mDNS/DNS-SD discovery\n│   └── server_test.go      # Tests\n├── config/\n│   └── agents.go           # MODIFIED — add ProviderType, APIConfig, MCPConfig\n└── polecat/\n    └── session_manager.go  # MODIFIED — branch on ProviderType in Start()\n```\n\n## Files to Create\n\n| File | Purpose |\n|------|---------|\n| `internal/llm/client.go` | Client interface, ChatRequest/Response, ToolDef, Message types |\n| `internal/llm/openai.go` | OpenAI-compatible HTTP client (Ollama, vLLM, OpenAI, Azure) |\n| `internal/llm/anthropic.go` | Anthropic Messages API client |\n| `internal/llm/factory.go` | NewClient() dispatches to correct implementation |\n| `internal/llm/client_test.go` | Unit tests with mock HTTP server |\n| `internal/agentloop/loop.go` | AgentLoop think→act→observe cycle |\n| `internal/agentloop/tools.go` | GT tool definitions as ToolDef structs |\n| `internal/agentloop/executor.go` | Tool call execution (file ops, git, gt, bd) |\n| `internal/agentloop/context.go` | Context window management (truncation, summarization) |\n| `internal/agentloop/loop_test.go` | Tests with mock LLM client |\n| `internal/mcp/server.go` | MCP tool server (SSE transport) |\n| `internal/mcp/transport.go` | Transport abstraction (SSE, stdio, WebSocket) |\n| `internal/mcp/discovery.go` | mDNS/DNS-SD for LAN discovery |\n| `internal/mcp/server_test.go` | MCP server tests |\n| `docs/examples/agents-api.json` | Example config for API-mode agents |\n| `docs/examples/agents-lan.json` | Example config for LAN GPU server setup |\n| `docs/examples/agents-mixed.json` | Example config for mixed CLI+API+MCP setup |\n\n## Files to Modify\n\n| File | Changes |\n|------|---------|\n| `internal/config/agents.go` | Add ProviderType, APIConfig, MCPConfig, extend AgentPresetInfo |\n| `internal/config/types.go` | Add ProviderType to RuntimeConfig resolution |\n| `internal/config/loader.go` | Handle provider_type in config resolution, validate API/MCP configs |\n| `internal/polecat/session_manager.go` | Branch on ProviderType in Start(), add startAPIAgent(), startMCPAgent() |\n| `go.mod` | Add HTTP/SSE/mDNS dependencies |\n\n## Security Considerations\n\n- **API keys**: Support `$ENV_VAR` syntax — never store raw keys in config\n- **MCP auth**: Bearer token required for network MCP servers\n- **Tool sandboxing**: `shell_exec` tool has a configurable allowlist of commands\n- **File access**: Tool executor restricts file ops to the worktree (no escape to /etc, ~, etc.)\n- **Network**: MCP server binds to configurable interface (default: 127.0.0.1, not 0.0.0.0)\n- **LAN discovery**: mDNS only advertises on local network, not public\n\n## Acceptance Criteria\n\n- [ ] `ProviderType` field added to `AgentPresetInfo` with backward compatibility (empty = \"cli\")\n- [ ] `APIConfig` and `MCPConfig` structs compile and validate\n- [ ] `llm.Client` interface defined with Chat, Stream, Ping, Close\n- [ ] `OpenAIClient` connects to Ollama and sends chat completions\n- [ ] `OpenAIClient` handles streaming responses (SSE)\n- [ ] `OpenAIClient` handles tool-use responses (function calling)\n- [ ] `AnthropicClient` connects to Anthropic API with tool_use\n- [ ] `NewClient()` factory dispatches correctly based on api_type\n- [ ] `Executor` executes all GT tools locally (gt_prime, gt_done, file_read, file_write, etc.)\n- [ ] `AgentLoop` runs think→act→observe cycle with mock LLM\n- [ ] `AgentLoop` respects MaxIterations limit\n- [ ] `AgentLoop` publishes Nostr heartbeats (when enabled)\n- [ ] `SessionManager.Start()` routes to startAPIAgent() for provider_type=api\n- [ ] `SessionManager.Start()` routes to startMCPAgent() for provider_type=mcp\n- [ ] Existing CLI flow unchanged (provider_type=cli or empty)\n- [ ] MCP server starts and accepts connections\n- [ ] MCP server authenticates with bearer token\n- [ ] MCP server exposes GT tools to remote clients\n- [ ] LAN discovery advertises/discovers MCP servers\n- [ ] API key env var resolution works ($OPENAI_API_KEY → actual value)\n- [ ] Config validation rejects invalid API/MCP configs\n- [ ] Example configs created for Ollama/LAN, vLLM, OpenAI, mixed setup\n- [ ] Unit tests for LLM client (mock HTTP server)\n- [ ] Unit tests for tool executor (mock filesystem)\n- [ ] Unit tests for agent loop (mock LLM client)\n- [ ] Integration test: Ollama on localhost → AgentLoop → tool execution → completion\n- [ ] Integration test: MCP server → remote tool call → local execution → response\n\n## Testing Strategy\n\n### Unit Tests\n- Mock HTTP server returning OpenAI-format responses (with/without tools)\n- Mock LLM client for AgentLoop tests\n- Executor tests with temp directory as worktree\n- Config validation tests for APIConfig, MCPConfig\n\n### Integration Tests\n- Start Ollama locally → create OpenAIClient → Chat() → verify response\n- Start MCP server → connect client → call tool → verify result\n- Full loop: AgentLoop with real Ollama → file_read → file_write → verify\n\n### LAN Tests (manual)\n- Configure Ollama on GPU server → set base_url → verify polecat works\n- Start MCP server on one machine → connect from another → verify tool calls\n\n## Dependencies\n\n- No new Go module dependencies for llm/ (standard `net/http`, `encoding/json`)\n- For MCP: may use `github.com/mark3labs/mcp-go` or implement minimal SSE transport\n- For mDNS: `github.com/hashicorp/mdns` or `github.com/grandcat/zeroconf`\n\n## Relationship to Nostr Refactor\n\nThis phase is complementary to the Nostr work:\n- Phase 2 (publisher/identity) provides the Nostr publisher that the agent loop uses for heartbeats\n- Phase 7 (chat/channels) provides NIP-17 DM-based work assignment that the agent loop consumes\n- The MCP server can be enhanced to bridge Nostr events (Phase 8)\n- In the fully Nostr-native architecture, the agent loop receives work via NIP-17 DMs instead of tmux nudges — the LLM client abstraction makes this a routing change, not an architecture change\n\nThe key insight: **the LLM doesn't need filesystem access; the agent loop (running locally) does**. This phase decouples \"where the model thinks\" from \"where the tools execute\".\"}
{"action":"create","id":"gt-nostr-p9","title":"[P9] Sunset Local-Only Paths","type":"task","priority":"medium","description":"# Phase 10: Sunset Local-Only Paths\n\n**Parent Epic**: gt-nostr-epic\n**Depends On**: gt-nostr-p3, gt-nostr-p4, gt-nostr-p5, gt-nostr-p6, gt-nostr-p7, gt-nostr-p8\n**Estimated Effort**: Medium\n\n## Objective\n\nAfter validating the Nostr-native paths in production, sunset the legacy local-only mechanisms. This is the final phase — feature-flagged removal of the old code paths, making Nostr the primary (but not sole) transport.\n\n## CRITICAL: Phased Rollout\n\nThis phase is NOT a big-bang cutover. Each subsystem gets its own feature flag:\n\n```bash\n# Master switch (already exists from Phase 1)\nGT_NOSTR_ENABLED=1\n\n# Per-subsystem sunset flags (new in this phase)\nGT_EVENTS_LOCAL=0          # Disable .events.jsonl writes\nGT_FEED_CURATOR=0          # Disable feed curator daemon\nGT_CONVOY_LOCAL=0           # Use Nostr queries instead of bd dep list\nGT_MAIL_LOCAL=0             # Disable beads-native mail routing\nGT_NUDGE_LOCAL=0            # Use NIP-17 DM instead of tmux nudge\n```\n\nDefault: ALL local paths remain ON during initial rollout. Operators opt-in to sunset one subsystem at a time.\n\n## Deliverables\n\n### 1. Event Log Sunset (`GT_EVENTS_LOCAL=0`)\n\n**What changes**:\n- `internal/events/events.go` → `write()` skips `.events.jsonl` append when `GT_EVENTS_LOCAL=0`\n- Nostr kind 30315 becomes the sole event sink\n- Local JSONL retained as readonly archive (not deleted)\n\n**Prerequisite checks before enabling**:\n- [ ] Verify all 20+ event types publishing correctly to relays\n- [ ] Verify spool drain working (no growing spool file)\n- [ ] Verify Flotilla Activity Feed rendering from Nostr events\n- [ ] Verify at least one write relay consistently available\n\n**Migration steps**:\n```go\nfunc write(event Event) error {\n    // Write to local file unless sunset\n    if config.IsEventsLocalEnabled() {\n        if err := writeToFile(event); err != nil {\n            return err\n        }\n    }\n    \n    // Publish to Nostr\n    if config.IsNostrEnabled() {\n        go publishToNostr(event)\n    }\n    \n    // At least one sink must be active\n    if !config.IsEventsLocalEnabled() && !config.IsNostrEnabled() {\n        return fmt.Errorf(\"no event sink configured: enable GT_EVENTS_LOCAL or GT_NOSTR_ENABLED\")\n    }\n    \n    return nil\n}\n```\n\n### 2. Feed Curator Sunset (`GT_FEED_CURATOR=0`)\n\n**What changes**:\n- `internal/feed/curator.go` → `Start()` returns immediately when `GT_FEED_CURATOR=0`\n- `.feed.jsonl` no longer written or maintained\n- Flotilla reads feed from Nostr `gtFeedLogs` store instead\n\n**Prerequisite checks**:\n- [ ] Verify `gtFeedLogs` store filters correctly (visibility=feed|both)\n- [ ] Verify deduplication/aggregation works at Nostr level (or in Flotilla store)\n- [ ] Verify no downstream consumers depend on `.feed.jsonl` file\n\n### 3. Convoy Observer Sunset (`GT_CONVOY_LOCAL=0`)\n\n**What changes**:\n- `internal/convoy/observer.go` → `CheckConvoysForIssue()` queries Nostr 30318 events instead of running `bd dep list` shell-outs\n- Remove `getTrackingConvoys()`, `runConvoyCheck()`, `getConvoyTrackedIssues()` functions (or gate behind flag)\n- New path: subscribe to kind 30318 and derive convoy state from Nostr\n\n**Migration**:\n```go\nfunc CheckConvoysForIssue(townRoot, issueID, observer string, ...) []string {\n    if config.IsConvoyLocalEnabled() {\n        // Legacy: shell out to bd dep list\n        return checkConvoysLocal(townRoot, issueID, observer, ...)\n    }\n    \n    // Nostr-native: query 30318 events\n    return checkConvoysNostr(issueID)\n}\n\nfunc checkConvoysNostr(issueID string) []string {\n    filter := nostr.Filter{\n        Kinds: []int{30318},\n        Tags:  nostr.TagMap{\"gt\": []string{\"1\"}, \"t\": []string{issueID}},\n    }\n    events := pool.QuerySync(ctx, filter)\n    // Extract convoy IDs from matching events\n    var convoyIDs []string\n    for _, e := range events {\n        d := e.Tags.GetFirst([]string{\"d\"}).Value()\n        convoyIDs = append(convoyIDs, d)\n    }\n    return convoyIDs\n}\n```\n\n### 4. Mail Router Sunset (`GT_MAIL_LOCAL=0`)\n\n**What changes**:\n- `internal/mail/router.go` → `Send()` routes through Nostr instead of beads:\n  - Protocol messages → kind 30320\n  - Queue messages → kind 30325\n  - Conversational DMs → NIP-17\n  - Channel messages → NIP-28 kind 42\n  - List/announce/group → NIP-28 channels + group definitions\n- Beads mail infrastructure (`hq-msg-*`, `hq-group-*`, `hq-q-*`) no longer written to\n- Existing beads messages retained as archive\n\n**Prerequisite checks**:\n- [ ] Verify all protocol events flowing via kind 30320\n- [ ] Verify work queue claims working via kind 30325\n- [ ] Verify NIP-17 DM delivery to all agent roles\n- [ ] Verify NIP-28 channel messages flowing\n- [ ] Verify no beads mail messages going unprocessed\n\n**This is the largest sunset** — the mail router has ~1400 lines with many routing patterns. The sunset should be gradual:\n1. First: sunset protocol messages (simplest, already dual-writing)\n2. Then: sunset queue messages\n3. Then: sunset channel/announce messages\n4. Finally: sunset DM routing (most complex)\n\n### 5. Tmux Nudge Sunset (`GT_NUDGE_LOCAL=0`)\n\n**What changes**:\n- `internal/tmux/` → `NudgeSession()` and `SendNotificationBanner()` replaced with NIP-17 DM delivery\n- No more tmux session injection for interrupts\n- Agent's Go process watches DM inbox for `priority=urgent` messages\n\n**Migration**:\n```go\nfunc NudgeAgent(actor, message string) error {\n    if config.IsNudgeLocalEnabled() {\n        // Legacy: tmux session injection\n        return tmux.NudgeSession(actor, message)\n    }\n    \n    // Nostr-native: send urgent DM\n    return nostr.SendInterrupt(actor, message)\n}\n```\n\n### 6. Documentation Updates\n\nUpdate all documentation to reflect relay-required operation:\n\n| Document | Changes |\n|----------|---------|\n| `docs/overview.md` | Add Nostr requirements, relay setup instructions |\n| `docs/design/architecture.md` | Update architecture diagrams with relay connections |\n| `docs/design/mail-protocol.md` | Mark as legacy, link to nostr-protocol.md |\n| `docs/beads-native-messaging.md` | Mark as legacy |\n| `README.md` | Add relay setup to quickstart |\n\n### 7. Health Check & Rollback\n\nAdd a health check command:\n\n```bash\ngt nostr status\n```\n\nOutputs:\n```\nNostr Status:\n  Enabled: true\n  Write Relays: wss://relay.example.com (connected ✅)\n  Read Relays: wss://relay.example.com (connected ✅)\n  Signer: NIP-46 bunker (connected ✅)\n  Spool: 0 events pending\n  \nSunset Status:\n  Events Local:  OFF (Nostr-only)\n  Feed Curator:  OFF (Nostr-only)\n  Convoy Local:  ON  (dual-write)\n  Mail Local:    ON  (dual-write)\n  Nudge Local:   OFF (Nostr-only)\n\nAgents:\n  deacon/        ready  (heartbeat 5s ago)\n  gastown/witness ready  (heartbeat 12s ago)\n  gastown/refinery busy  (heartbeat 8s ago, issue: gt-123)\n```\n\nRollback: set `GT_NOSTR_ENABLED=0` to disable all Nostr paths and fall back to local-only operation. Local paths are always available as fallback.\n\n## Files to Modify\n\n| File | Changes |\n|------|---------|\n| `internal/events/events.go` | Feature-flag local writes |\n| `internal/feed/curator.go` | Feature-flag curator start |\n| `internal/convoy/observer.go` | Add Nostr query path, feature-flag local path |\n| `internal/mail/router.go` | Feature-flag beads mail, add Nostr routing |\n| `internal/tmux/` | Feature-flag nudge, add DM interrupt path |\n| `internal/config/env.go` | Add GT_EVENTS_LOCAL, GT_FEED_CURATOR, GT_CONVOY_LOCAL, GT_MAIL_LOCAL, GT_NUDGE_LOCAL |\n| `docs/overview.md` | Update for Nostr-native operation |\n| `docs/design/architecture.md` | Update architecture diagrams |\n| `docs/design/mail-protocol.md` | Mark as legacy |\n| `docs/beads-native-messaging.md` | Mark as legacy |\n\n## Files to Create\n\n| File | Purpose |\n|------|---------|\n| `internal/nostr/health.go` | Health check implementation |\n| CLI: `gt nostr status` | Health check command |\n\n## Acceptance Criteria\n\n- [ ] `GT_EVENTS_LOCAL=0` disables .events.jsonl writes\n- [ ] `GT_FEED_CURATOR=0` disables feed curator daemon\n- [ ] `GT_CONVOY_LOCAL=0` uses Nostr queries instead of bd dep list\n- [ ] `GT_MAIL_LOCAL=0` routes all mail through Nostr\n- [ ] `GT_NUDGE_LOCAL=0` uses NIP-17 DM interrupts\n- [ ] Safety: at least one sink always active (error if no local AND no Nostr)\n- [ ] Safety: `GT_NOSTR_ENABLED=0` reverts to fully local operation\n- [ ] `gt nostr status` shows connection/spool/sunset status\n- [ ] Each subsystem sunset independently testable\n- [ ] Existing local files retained as readonly archives (not deleted)\n- [ ] Documentation updated for relay-required operation\n- [ ] Mail router sunset is phased: protocol → queues → channels → DMs\n- [ ] Rollback tested: disable Nostr → everything works locally\n- [ ] Integration test: full Nostr-only operation with all local paths disabled"}
